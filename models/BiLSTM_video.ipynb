{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import _pickle as pickle\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"../\"\n",
    "\n",
    "DATA_DIR = ROOT_DIR\n",
    "RESULTS_DIR = ROOT_DIR + \"results/\"\n",
    "\n",
    "# Train - 1460 (1168 + 292) videos \n",
    "# Test - 252 videos \n",
    "\n",
    "TRAINING_DATA = DATA_DIR + \"video_training_data.p\" # each read gives labelled video [(segment, label), segment_2, ...]\n",
    "VALIDATION_DATA = DATA_DIR + \"video_validation_data.p\" \n",
    "TEST_DATA = DATA_DIR + \"video_testing_data.p\" # each read gives video [(segment), segment_2, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_video_data(f):    \n",
    "    is_end_reached = False\n",
    "    \n",
    "    try:\n",
    "        video = pickle.load(f) # [(segment, label), ...]\n",
    "    except (EOFError):\n",
    "        is_end_reached = True\n",
    "        return [], is_end_reached\n",
    "    \n",
    "    return video, is_end_reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temporal Model (RNN, LSTM, GRU):**\n",
    "- [ ] Add dropout\n",
    "- [ ] Add stacking / another lstm\n",
    "- [ ] No temporal pooling\n",
    "- [ ] Max pooling\n",
    "- [ ] Avg pooling\n",
    "- [ ] [Concat pooling](https://medium.com/@sonicboom8/sentiment-analysis-with-variable-length-sequences-in-pytorch-6241635ae130)\n",
    "- [ ] CS4248 12-rnn slide 32: Use pooled hidden states (segment level) in another RNN, and predict for each resultatnt hidden state. \n",
    "\n",
    "**Try out models:**\n",
    "- [ ] RNN\n",
    "- [ ] GRU\n",
    "- [ ] [QRNN](https://github.com/salesforce/pytorch-qrnn)\n",
    "- [ ] Nested LSTM\n",
    "- [ ] TCN\n",
    "\n",
    "\n",
    "[LSTM vs GRU](https://blog.floydhub.com/gru-with-pytorch/) explanation and comparison article\n",
    "\n",
    "\n",
    "**Training:**\n",
    "- [ ] Shuffle data\n",
    "- [ ] Xavier normal initialisation\n",
    "- [ ] Xavier uniform initialisation\n",
    "\n",
    "\n",
    "Yash- high validation accuracy for **hidden dim 50**. But test results are bad.\n",
    "\n",
    "\n",
    "Don't use the SIL frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassPredictor(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ClassPredictor, self).__init__()\n",
    "        \n",
    "        hidden_1 = 120\n",
    "        hidden_2 = 80\n",
    "        \n",
    "#         self.temp = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/nn.html#torch.nn.Linear\n",
    "        self.fc1 = nn.Linear(input_size, hidden_1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=hidden_1)\n",
    "        self.l_relu1 = nn.LeakyReLU()\n",
    "        self.dout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=hidden_2)\n",
    "        self.l_relu2 = nn.LeakyReLU()\n",
    "        \n",
    "        self.out = nn.Linear(hidden_2, num_classes)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "            nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n",
    "            nn.init.xavier_uniform_(self.out.weight)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        ## x: (input_size)\n",
    "#         return self.temp(x)\n",
    "        \n",
    "        a1 = self.fc1(x)\n",
    "#         b1 = self.bn1(a1)\n",
    "        h1 = self.l_relu1(a1)\n",
    "        dout1 = self.dout1(h1)\n",
    "\n",
    "        a2 = self.fc2(dout1)\n",
    "#         b2 = self.bn2(a2)\n",
    "        h2 = self.l_relu2(a2)\n",
    "        \n",
    "        # y: (num_classes)\n",
    "        y = self.out(h2)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional recurrent neural network (many-to-one)\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        drop_prob = 0\n",
    "        \n",
    "        ## https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM\n",
    "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=True, \n",
    "                            batch_first=True, bias=True, dropout=drop_prob)\n",
    "        \n",
    "        ## DNN for class prediction\n",
    "        self.fc = ClassPredictor(hidden_size * 2, num_classes)\n",
    " \n",
    "\n",
    "    ## https://pytorch.org/docs/stable/nn.init.html\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        #h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)\n",
    "        #c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)\n",
    "\n",
    "        h0 = torch.empty(self.num_layers * 2, batch_size, self.hidden_size).double()\n",
    "        h0 = nn.init.orthogonal_(h0) # orthogonal_, xavier_normal_, xavier_uniform_\n",
    "        \n",
    "        c0 = torch.empty(self.num_layers * 2, batch_size, self.hidden_size).double()\n",
    "        c0 = nn.init.orthogonal_(c0) # orthogonal_, xavier_normal_, xavier_uniform_\n",
    "\n",
    "        h0 = h0.requires_grad_().cuda()\n",
    "        c0 = c0.requires_grad_().cuda()\n",
    "        \n",
    "        return h0, c0\n",
    " \n",
    "\n",
    "    def forward(self, x, segment_indices):\n",
    "        ## x: (batch_size, seq_len, feature_len)\n",
    "        ## segment_indices: (num_segments, 2)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        ## Set initial states\n",
    "        ## h0, c0: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        h0, c0 = self.init_hidden_state(batch_size)\n",
    "        \n",
    "        ## Forward propagate LSTM\n",
    "        ## out: tensor of shape (batch_size, seq_length, hidden_size * 2)\n",
    "        out, _ = self.bilstm(x, (h0, c0))  \n",
    "        \n",
    "        ## Use hidden states of each segment to predict their labels\n",
    "        segment_outputs = []\n",
    "        for (start, end) in segment_indices:\n",
    "            hidden_states = out[:, start:end, :]\n",
    "            \n",
    "            ## Compute the hidden state by doing temporal pooling over all time steps\n",
    "            ## pool_out: (hidden_size * 2)\n",
    "            \n",
    "            pool_out = torch.mean(hidden_states, dim=1).squeeze() # adaptive_avg_pool1d\n",
    "#             pool_out = F.adaptive_max_pool1d(hidden_states.permute(0,2,1), 1).squeeze()\n",
    "\n",
    "            ## concat_pool_out: (hidden_size * 2 * 2)\n",
    "#             concat_pool_out = torch.cat([max_pool_out, avg_pool_out])\n",
    "\n",
    "#             final_hidden_out = out[:, end - 1, :]\n",
    "            \n",
    "            ## output: (num_classes)\n",
    "            output = self.fc(pool_out)\n",
    "            \n",
    "            segment_outputs.append(output)\n",
    "\n",
    "        \n",
    "        ## segment_outputs: (num_segments, num_classes)\n",
    "        segment_outputs = torch.stack(segment_outputs)\n",
    "        \n",
    "        return segment_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiGRU, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        drop_prob = 0\n",
    "        \n",
    "        ## https://pytorch.org/docs/stable/nn.html#torch.nn.GRU\n",
    "        self.bigru =nn.GRU(input_size, hidden_size, num_layers, bidirectional=True, \n",
    "                            batch_first=True, bias=True, dropout=drop_prob)\n",
    "        \n",
    "        ## DNN for class prediction\n",
    "        self.fc = ClassPredictor(hidden_size * 2, num_classes)\n",
    " \n",
    "\n",
    "    ## https://pytorch.org/docs/stable/nn.init.html\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        #h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)\n",
    "\n",
    "        h0 = torch.empty(self.num_layers * 2, batch_size, self.hidden_size).double()\n",
    "        h0 = nn.init.orthogonal_(h0) # orthogonal_, xavier_normal_, xavier_uniform_\n",
    "        h0 = h0.requires_grad_().cuda()\n",
    "        \n",
    "        return h0\n",
    " \n",
    "\n",
    "    def forward(self, x, segment_indices):\n",
    "        ## x: (batch_size, seq_len, feature_len)\n",
    "        ## segment_indices: (num_segments, 2)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        ## Set initial states\n",
    "        ## h0: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        h0 = self.init_hidden_state(batch_size)\n",
    "        \n",
    "        ## Forward propagate\n",
    "        ## out: tensor of shape (batch_size, seq_length, hidden_size * 2)\n",
    "        out, _ = self.bigru(x, h0)  \n",
    "        \n",
    "        ## Use hidden states of each segment to predict their labels\n",
    "        segment_outputs = []\n",
    "        for (start, end) in segment_indices:\n",
    "            hidden_states = out[:, start:end, :]\n",
    "            \n",
    "            ## Compute the hidden state by doing temporal pooling over all time steps\n",
    "            ## pool_out: (hidden_size * 2)\n",
    "            \n",
    "#             pool_out = torch.mean(hidden_states, dim=1).squeeze() # adaptive_avg_pool1d\n",
    "            pool_out = F.adaptive_max_pool1d(hidden_states.permute(0,2,1), 1).squeeze()\n",
    "\n",
    "            ## concat_pool_out: (hidden_size * 2 * 2)\n",
    "#             concat_pool_out = torch.cat([max_pool_out, avg_pool_out])\n",
    "\n",
    "#             final_hidden_out = out[:, end - 1, :]\n",
    "            \n",
    "            ## output: (num_classes)\n",
    "            output = self.fc(pool_out)\n",
    "            \n",
    "            segment_outputs.append(output)\n",
    "\n",
    "        \n",
    "        ## segment_outputs: (num_segments, num_classes)\n",
    "        segment_outputs = torch.stack(segment_outputs)\n",
    "        \n",
    "        return segment_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_states = v[:, 0:3, :]\n",
    "\n",
    "# max_pool = F.adaptive_max_pool1d(hidden_states.permute(0,2,1), 1).squeeze()\n",
    "\n",
    "# avg_pool = F.adaptive_avg_pool1d(hidden_states.permute(0,2,1), 1).squeeze()\n",
    "# a_pool = torch.mean(hidden_states, dim=1).squeeze()\n",
    "\n",
    "# a_pool\n",
    "# avg_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on entire videos (sequence of segments which are sequence of frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_inputs(video):\n",
    "    segments = [] # segments (list of frames) in the video\n",
    "    labels = [] # labels of each segment\n",
    "    segment_indices = []\n",
    "    offset = 0\n",
    "    for segment_num in range(len(video)):\n",
    "        segments.append(video[segment_num][0])\n",
    "        labels.append(video[segment_num][1])\n",
    "        segment_indices.append((offset, offset + video[segment_num][0].shape[0]))\n",
    "\n",
    "        offset += video[segment_num][0].shape[0]\n",
    "        \n",
    "    # Load frames as tensors with gradient accumulation abilities\n",
    "    input_frames = torch.cat(segments, 0).unsqueeze(0).requires_grad_().cuda() # unsqueeze to add batch dim\n",
    "    labels = torch.Tensor(labels).long().cuda()\n",
    "    segment_indices = torch.IntTensor(segment_indices).cuda()\n",
    "    \n",
    "    return input_frames, labels, segment_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, folder):\n",
    "    filename = folder + 'model_checkpoint.pth'\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, folder + 'model_best.pth')\n",
    "\n",
    "def train_model(model, num_epochs=10, train_data_file=TRAINING_DATA, validation_data_file=VALIDATION_DATA):\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    training_accuracies = []\n",
    "    validation_accuracies = []\n",
    "    best_accuracy = -float(\"inf\")\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print('======================================================================')\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "\n",
    "        try:\n",
    "            train_f.close()    \n",
    "        except(NameError):\n",
    "            pass   \n",
    "        \n",
    "        train_f = open(train_data_file, 'rb')\n",
    "        should_epoch_end = False\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        video_num = 0\n",
    "        epoch_training_losses = []\n",
    "\n",
    "        model.train()\n",
    "        while not should_epoch_end:\n",
    "            video, should_epoch_end = get_next_video_data(train_f)\n",
    "            if should_epoch_end:\n",
    "                break\n",
    "            \n",
    "            inputs, labels, segment_indices = transform_to_inputs(video)\n",
    "\n",
    "            outputs = model(inputs, segment_indices)\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_training_losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            video_num += 1\n",
    "            if video_num % 150 == 0:\n",
    "                print('    Video: {}/1168  Loss: {}'.format(video_num, np.mean(epoch_training_losses))) \n",
    "\n",
    "        train_f.close()            \n",
    "        \n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        try:\n",
    "            val_f.close()    \n",
    "        except(NameError):\n",
    "            pass  \n",
    "            \n",
    "        val_f = open(validation_data_file, 'rb')\n",
    "        model.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        is_file_end = False\n",
    "\n",
    "        epoch_validation_losses = []\n",
    "        while not is_file_end:\n",
    "            video, is_file_end = get_next_video_data(val_f)\n",
    "            if is_file_end:\n",
    "                break\n",
    "            \n",
    "            inputs, labels, segment_indices = transform_to_inputs(video)\n",
    "        \n",
    "            outputs = model(inputs, segment_indices)\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            epoch_validation_losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_f.close()\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        \n",
    "        \n",
    "        # Print loss and accuracy\n",
    "        training_losses.append(np.mean(epoch_training_losses))\n",
    "        validation_losses.append(np.mean(epoch_validation_losses))\n",
    "        training_accuracies.append(train_accuracy)\n",
    "        validation_accuracies.append(val_accuracy)\n",
    "        \n",
    "\n",
    "        scheduler.step(validation_losses[-1])\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(f' Training Loss: {training_losses[-1]}  Validation Loss: {validation_losses[-1]}')\n",
    "        print('Training Accuracy: {:.3f}%   Validation Accuracy: {:.3f}%'.format(train_accuracy, val_accuracy))        \n",
    "        print('Epoch took {:.2f} minutes'.format((end - start) / 60))\n",
    "        \n",
    "        is_best = val_accuracy > best_accuracy\n",
    "        best_accuracy = max(val_accuracy, best_accuracy)\n",
    "        save_checkpoint({\n",
    "            'next_epoch_idx': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best, RESULTS_DIR + model_time + '/')\n",
    "\n",
    "        print('Best Accuracy: {:.3f}%'.format(best_accuracy))\n",
    "\n",
    "    return training_losses, validation_losses, training_accuracies, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Epoch: 0\n",
      "    Video: 150/1168  Loss: 3.7324353049546093\n",
      "    Video: 300/1168  Loss: 3.628117647855784\n",
      "    Video: 450/1168  Loss: 3.5352987730026446\n",
      "    Video: 600/1168  Loss: 3.4749442856790695\n",
      "    Video: 750/1168  Loss: 3.4108165886221613\n",
      "    Video: 900/1168  Loss: 3.3352620612763015\n",
      "    Video: 1050/1168  Loss: 3.2803796321264462\n",
      " Training Loss: 3.2371355842004093  Validation Loss: 2.7261165947780137\n",
      "Training Accuracy: 13.753%   Validation Accuracy: 22.567%\n",
      "Epoch took 362.85424995422363 seconds\n",
      "Best Accuracy: 22.567%\n",
      "======================================================================\n",
      "Epoch: 1\n",
      "    Video: 150/1168  Loss: 2.6116164990254163\n",
      "    Video: 300/1168  Loss: 2.6745885848338595\n",
      "    Video: 450/1168  Loss: 2.630632439741108\n",
      "    Video: 600/1168  Loss: 2.624889013738243\n",
      "    Video: 750/1168  Loss: 2.5923272305027454\n",
      "    Video: 900/1168  Loss: 2.544291327840017\n",
      "    Video: 1050/1168  Loss: 2.526366070595798\n",
      " Training Loss: 2.5018415326345864  Validation Loss: 2.2029042952912627\n",
      "Training Accuracy: 25.491%   Validation Accuracy: 32.581%\n",
      "Epoch took 363.02390599250793 seconds\n",
      "Best Accuracy: 32.581%\n",
      "======================================================================\n",
      "Epoch: 2\n",
      "    Video: 150/1168  Loss: 2.1958981692603\n",
      "    Video: 300/1168  Loss: 2.2203760923415077\n",
      "    Video: 450/1168  Loss: 2.2051852961592275\n",
      "    Video: 600/1168  Loss: 2.215337174770198\n",
      "    Video: 750/1168  Loss: 2.197530445472775\n",
      "    Video: 900/1168  Loss: 2.1766870798750633\n",
      "    Video: 1050/1168  Loss: 2.174633593010795\n",
      " Training Loss: 2.1675385598412635  Validation Loss: 1.9670633741267625\n",
      "Training Accuracy: 32.385%   Validation Accuracy: 37.659%\n",
      "Epoch took 365.00879883766174 seconds\n",
      "Best Accuracy: 37.659%\n",
      "======================================================================\n",
      "Epoch: 3\n",
      "    Video: 150/1168  Loss: 1.9642647738202428\n",
      "    Video: 300/1168  Loss: 1.9895214198208335\n",
      "    Video: 450/1168  Loss: 1.9822816627560467\n",
      "    Video: 600/1168  Loss: 1.98945459694841\n",
      "    Video: 750/1168  Loss: 1.9734783892924403\n",
      "    Video: 900/1168  Loss: 1.9587451746704883\n",
      "    Video: 1050/1168  Loss: 1.9535109111752658\n",
      " Training Loss: 1.951505428047566  Validation Loss: 1.7858974110630645\n",
      "Training Accuracy: 36.450%   Validation Accuracy: 42.031%\n",
      "Epoch took 383.11315655708313 seconds\n",
      "Best Accuracy: 42.031%\n",
      "======================================================================\n",
      "Epoch: 4\n",
      "    Video: 150/1168  Loss: 1.7706022240624948\n",
      "    Video: 300/1168  Loss: 1.7963380930610933\n",
      "    Video: 450/1168  Loss: 1.8024825210273254\n",
      "    Video: 600/1168  Loss: 1.8187021870159075\n",
      "    Video: 750/1168  Loss: 1.8048358541917702\n",
      "    Video: 900/1168  Loss: 1.7845471064462077\n",
      "    Video: 1050/1168  Loss: 1.7836637136015048\n",
      " Training Loss: 1.782965836104477  Validation Loss: 1.6891432642129387\n",
      "Training Accuracy: 39.897%   Validation Accuracy: 42.595%\n",
      "Epoch took 380.68435764312744 seconds\n",
      "Best Accuracy: 42.595%\n",
      "======================================================================\n",
      "Epoch: 5\n",
      "    Video: 150/1168  Loss: 1.644108646170221\n",
      "    Video: 300/1168  Loss: 1.6389124698155468\n",
      "    Video: 450/1168  Loss: 1.6426134587265142\n",
      "    Video: 600/1168  Loss: 1.652976879009847\n",
      "    Video: 750/1168  Loss: 1.6377845239204605\n",
      "    Video: 900/1168  Loss: 1.6331359377338392\n",
      "    Video: 1050/1168  Loss: 1.627613739340316\n",
      " Training Loss: 1.6289939790276178  Validation Loss: 1.5985850518185656\n",
      "Training Accuracy: 44.105%   Validation Accuracy: 45.769%\n",
      "Epoch took 379.08077788352966 seconds\n",
      "Best Accuracy: 45.769%\n",
      "======================================================================\n",
      "Epoch: 6\n",
      "    Video: 150/1168  Loss: 1.538811918809438\n",
      "    Video: 300/1168  Loss: 1.5678758460881355\n",
      "    Video: 450/1168  Loss: 1.5635030804046022\n",
      "    Video: 600/1168  Loss: 1.5723275063551891\n",
      "    Video: 750/1168  Loss: 1.5635946911883518\n",
      "    Video: 900/1168  Loss: 1.5583107842295183\n",
      "    Video: 1050/1168  Loss: 1.5554193887408825\n",
      " Training Loss: 1.554816523761119  Validation Loss: 1.5345719441781707\n",
      "Training Accuracy: 46.509%   Validation Accuracy: 49.013%\n",
      "Epoch took 392.4348921775818 seconds\n",
      "Best Accuracy: 49.013%\n",
      "======================================================================\n",
      "Epoch: 7\n",
      "    Video: 150/1168  Loss: 1.3936055292778615\n",
      "    Video: 300/1168  Loss: 1.447261382490518\n",
      "    Video: 450/1168  Loss: 1.4487828894071173\n",
      "    Video: 600/1168  Loss: 1.46756240665349\n",
      "    Video: 750/1168  Loss: 1.4766365938796668\n",
      "    Video: 900/1168  Loss: 1.469616102415301\n",
      "    Video: 1050/1168  Loss: 1.4654542810600732\n",
      " Training Loss: 1.4685963842988852  Validation Loss: 1.4976385220997805\n",
      "Training Accuracy: 47.923%   Validation Accuracy: 50.000%\n",
      "Epoch took 398.0012969970703 seconds\n",
      "Best Accuracy: 50.000%\n",
      "======================================================================\n",
      "Epoch: 8\n",
      "    Video: 150/1168  Loss: 1.3587228305474124\n",
      "    Video: 300/1168  Loss: 1.358280125614466\n",
      "    Video: 450/1168  Loss: 1.3771487547855692\n",
      "    Video: 600/1168  Loss: 1.4014924770977737\n",
      "    Video: 750/1168  Loss: 1.3932051068593359\n",
      "    Video: 900/1168  Loss: 1.3803711573358755\n",
      "    Video: 1050/1168  Loss: 1.3843758645995698\n",
      " Training Loss: 1.3878005425896989  Validation Loss: 1.4500631768994725\n",
      "Training Accuracy: 50.610%   Validation Accuracy: 50.635%\n",
      "Epoch took 383.8811264038086 seconds\n",
      "Best Accuracy: 50.635%\n",
      "======================================================================\n",
      "Epoch: 9\n",
      "    Video: 150/1168  Loss: 1.2888602284721116\n",
      "    Video: 300/1168  Loss: 1.3149165176675621\n",
      "    Video: 450/1168  Loss: 1.3136127131870436\n",
      "    Video: 600/1168  Loss: 1.327942758188531\n",
      "    Video: 750/1168  Loss: 1.3242548679743822\n",
      "    Video: 900/1168  Loss: 1.3148720932026545\n",
      "    Video: 1050/1168  Loss: 1.3119930256317296\n",
      " Training Loss: 1.3194161035073793  Validation Loss: 1.4349182591217173\n",
      "Training Accuracy: 51.476%   Validation Accuracy: 51.340%\n",
      "Epoch took 375.4079248905182 seconds\n",
      "Best Accuracy: 51.340%\n",
      "======================================================================\n",
      "Epoch: 10\n",
      "    Video: 150/1168  Loss: 1.230950636738219\n",
      "    Video: 300/1168  Loss: 1.2580158547693414\n",
      "    Video: 450/1168  Loss: 1.26882600487366\n",
      "    Video: 600/1168  Loss: 1.2704256187535843\n",
      "    Video: 750/1168  Loss: 1.265418740341552\n",
      "    Video: 900/1168  Loss: 1.2480834251737027\n",
      "    Video: 1050/1168  Loss: 1.2446801191908927\n",
      " Training Loss: 1.2444084438433636  Validation Loss: 1.4054297042509043\n",
      "Training Accuracy: 53.527%   Validation Accuracy: 51.410%\n",
      "Epoch took 377.4491112232208 seconds\n",
      "Best Accuracy: 51.410%\n",
      "======================================================================\n",
      "Epoch: 11\n",
      "    Video: 150/1168  Loss: 1.1384085200401273\n",
      "    Video: 300/1168  Loss: 1.177571613083472\n",
      "    Video: 450/1168  Loss: 1.174201373323885\n",
      "    Video: 600/1168  Loss: 1.1907874775259635\n",
      "    Video: 750/1168  Loss: 1.181457975447802\n",
      "    Video: 900/1168  Loss: 1.1746965375113865\n",
      "    Video: 1050/1168  Loss: 1.175943778191127\n",
      " Training Loss: 1.1837087498333025  Validation Loss: 1.367327787933562\n",
      "Training Accuracy: 55.842%   Validation Accuracy: 53.032%\n",
      "Epoch took 375.90312695503235 seconds\n",
      "Best Accuracy: 53.032%\n",
      "======================================================================\n",
      "Epoch: 12\n",
      "    Video: 150/1168  Loss: 1.149885228936356\n",
      "    Video: 300/1168  Loss: 1.1551868620153702\n",
      "    Video: 450/1168  Loss: 1.1540090714895914\n",
      "    Video: 600/1168  Loss: 1.1605607062894197\n",
      "    Video: 750/1168  Loss: 1.1559137624984068\n",
      "    Video: 900/1168  Loss: 1.142977864198239\n",
      "    Video: 1050/1168  Loss: 1.1415678851499613\n",
      " Training Loss: 1.1539230405358967  Validation Loss: 1.336449371866128\n",
      "Training Accuracy: 56.514%   Validation Accuracy: 53.949%\n",
      "Epoch took 374.678359746933 seconds\n",
      "Best Accuracy: 53.949%\n",
      "======================================================================\n",
      "Epoch: 13\n",
      "    Video: 150/1168  Loss: 1.0859648994851852\n",
      "    Video: 300/1168  Loss: 1.0748992644889954\n",
      "    Video: 450/1168  Loss: 1.0817678083828866\n",
      "    Video: 600/1168  Loss: 1.098587341877511\n",
      "    Video: 750/1168  Loss: 1.099948274570835\n",
      "    Video: 900/1168  Loss: 1.0896076380522215\n",
      "    Video: 1050/1168  Loss: 1.0840316659120521\n",
      " Training Loss: 1.0904551044503554  Validation Loss: 1.3309854023560883\n",
      "Training Accuracy: 57.469%   Validation Accuracy: 54.654%\n",
      "Epoch took 380.3128192424774 seconds\n",
      "Best Accuracy: 54.654%\n",
      "======================================================================\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Video: 150/1168  Loss: 1.0663315379147926\n",
      "    Video: 300/1168  Loss: 1.0504082973824427\n",
      "    Video: 450/1168  Loss: 1.0541910218322392\n",
      "    Video: 600/1168  Loss: 1.0507378966715641\n",
      "    Video: 750/1168  Loss: 1.0435020790094993\n",
      "    Video: 900/1168  Loss: 1.0358353011666774\n",
      "    Video: 1050/1168  Loss: 1.039703702512635\n",
      " Training Loss: 1.0490108904302256  Validation Loss: 1.2933967274763571\n",
      "Training Accuracy: 59.378%   Validation Accuracy: 54.937%\n",
      "Epoch took 377.22947549819946 seconds\n",
      "Best Accuracy: 54.937%\n",
      "\n",
      "Saved trained model to ../results/2020-04-05_18-03-28/bidirectional_video_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_time = str(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "os.mkdir(RESULTS_DIR + model_time)\n",
    "\n",
    "## Model Architecture\n",
    "input_dim = 400  # dimension of an i3D video frame\n",
    "hidden_dim = 80 # dimension of hidden state\n",
    "layer_dim = 1    # number of stacked layers\n",
    "output_dim = 48  # number of sub-action labels\n",
    "\n",
    "\n",
    "# model = BiLSTM(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = BiGRU(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "model = model.double().cuda() # transform the model parameters to double precision\n",
    "\n",
    "\n",
    "## Loss function\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "## Optimizer\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.0002\n",
    "momentum = 0.9\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "\n",
    "\n",
    "## Learning Rate Scheduler\n",
    "patience = 2\n",
    "decrease_factor = 0.7\n",
    "min_learning_rate = 0.00005\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', \n",
    "                              patience=patience, min_lr=min_learning_rate, factor=decrease_factor,\n",
    "                              verbose=True)\n",
    "\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "training_losses, validation_losses, training_accuracies, validation_accuracies = train_model(model,num_epochs=num_epochs) # TODO: batch_sizes\n",
    "\n",
    "path = RESULTS_DIR + model_time + \"/bidirectional_video_model.pth\"\n",
    "torch.save(model.state_dict(), path)\n",
    "print(\"\\nSaved trained model to\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24503fb2b08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAGDCAYAAADtZ0xmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3hUVf7H8fc3jQCh954AinQIoUlXFLEX1gYqRV3brmvZ1Z+ra1ndtcviunawgZW1rEoRpSMlIB0hlAChht4h5fz+uBcImEACmdwkfF7PM4935t655zt3JvKZM+eea845REREREQk98KCLkBEREREpKhRiBYRERERySOFaBERERGRPFKIFhERERHJI4VoEREREZE8UogWEREREckjhWgROYaZTTCzWwugnf5mNiXU7eTQdriZ7TGzuvm5bZDMrKGZ5fucpWbW08ySs9xfamZdcrPtKbT1jpk9cqrPP8F+nzaz9/J7vzm01d3MFhVEW7lhZhFm5swsNuhacmJmU8ysf9B1iORVRNAFiBR1ZjYBaAlUd84dDLicQPlBJcU592g+73dPlrulgINAhn//98654XnZn3MuA4jJ723PBM65RvmxH/+LWj/nXPcs+w75l7dQc85NAJoGXYeIhJ56okVOg9+70wVwwOUhauOM/7LrnIs5fAPWAJdleew3AVrHTEREQk0hWuT03AxMB94Dbjn8oJl1MLONZhae5bGrzGy+vxxmZg+b2Qoz22pmn5lZRX9drP/z6yAzWwP85D/+ub/PnWY2ycyaZtl3JTP7n5ntMrNZ/s/XU7KsP8fMfjCzbf7P8dee5HU1MLOZfltfH67tRHWY2e1AX+Av/vCH//mP1zGz/5pZqv9a/521ITN70cy2m9kqM+udl4OfZR9Pm9mnZvaxme0G+plZRzObbmY7zGyDmQ0xs0h/+2N+4jazj/z1o8xst5n9bGZxed3WX9/bzJb5x+dVM5ua00/Vuazx92a23D9GQ7I8N9zMXvGP6QrgohMcn0fN7JPjHnvNzF72l281syX+61lhJxjOY2YpZtbdXy5lZh/6tS0C2mTT7kp/v4vM7HL/8ebAv4Eu/mdlS5Zj+0SW59/hv/atZvaVmdXIzbE5GTO70q9nh5n9ZGaNsqx7xMzW+39Lv2Z5rR3MbI7/+CYzeyGHfR8//CXFzO43swX+Z+JjMytxgtpu9dvd7n/G6mRZ929/f4f/zs/Nsi7CzB7z379dZpZoZjWz7LpXbo6Vef9vesTfzxYz+8TMKvjrGvrH/Tb/GK03s/uyPDfa/wxvMLN1ZvaymUVlWX+1mc3161tuZhdmaTrOzKb5n5XRluX/OSKFlnNON910O8UbsBy4Cy88pAHVsqxbAVyQ5f7nwMP+8p/wwndtoATwJvCxvy4Wr2f7A6A0UNJ/fCBQxt9+MDA3y74/8W+lgCbAWmCKv660f38A3hCueGAL0DSH1zQBWAc08587Evgoy/oT1fEe8HSW++HAPOAVf1/RQGd/XX//mN3mb3cnsB6wkxzzZKDncY89DRwCLsPrHCgJtAXa+6+5PrAMuMffPsI/xrH+/Y/8Y5IARAKfHn7Nedy2KrAbuMJfd7//Gvvn8FpyU+PXQDn/c7Ht8GsH7gEW4X2GKgGTAJdDO/WBPUDpLPveDCT49y/ztzHgPGA/0MJf1xNIzrKvFKC7v/yi/3mpANQDFh+37bVADf89udGvoZq/7lZgwnF1fgQ84S9f6NfYyv/c/Af4KTfHJpvX/zTwnr/c2K/jPP89esQ/7pF4wzBW4w3NAogD6vvLs4Ab/OUyQPsc2srueE0Hqvvv0zLg1hye2wdYCjTyX+MTwOQs628CKvrrHsL7Oy3hr/s/vL+1s/zj3SrLtnk5Vg8CU4Fa/nF/F/jQX9fQ39eHeP+vaQlszfJ5+AcwDaiC97cwA3jcX3cusAM436+vDtDIXzcFSPJrLwVMJsv/R3TTrbDeAi9AN92K6g3ojBeQKvv3fwXuy7L+aWCov1wG2AvU8+8vAc7Psm0Nf18RHA3R9U/Qdnl/m3J4ATTt8D9IWdo+HKKvy/oPsf/Ym4f/cctm3xOAZ7Pcb4IXUMNPVId//z2ODdEdgVQgIpvn9geWZ7lfyt9X9ZMc9+TjA4D/en86yfMeBD73l7MLxm9k2fZyYOEpbDuQY0OPARvIIUTnssYOWdb/F3jQX55EljAGXEwOIdpfPx240V/uDSw7wbbfAnf7yycK0Wuyvhd4XyiTT7DfhcAl/vLJQvT7wD+yrCuLNw6+9smOTTbtZg3RTwIjsqwLAzbi/T03AjbhBb2I4/YxDfgbUOkk72F2x+v6LPdfBv6dw3N/AG7Jcj8Cb/x/rWy2NbwvbE39+ysOH9vjtsvrsUoCumW5X8evIYyjIbrhca/nTX95NXBhlnWX4P+N44XxF3Jocwp+B4N//4/At7n5m9FNtyBvGs4hcupuAcY657b490eQZUiHf/9q/6fbq4E5zrnV/rp6wJf+z8k78EJ1BlAty/PXHl7wf7p/9vBPtXhBEqAyXq9PRNbtj1uuB7Q/3JbfXl+8nrGcZH3+arxeusonqSM7dYDVzrn0HNZvPLzgnNvnL57qSXxZaz48hOU784ae7AKeOkGdx9QC7DtJHTltWzNrHc45hxeispXLGnPVFt77dCIjgBv85RuBI2PJzexSM5th3nCfHXi9wCc6VofVOFEN5s3AMi/L5+6cXO4XvNd3ZH/OuV3Adrwe0sPy8p7ltN9MvPeolnNuKfAA3vuw2R96cfjvZADeF8ql5g11ujiXryMvddYDXstyvLYAmXhfHDCzv/hDPXbiHYvSHD2edfCC9OnWUBf4X5YaFuAF56pZtjn+PT88bKQGx34GVnP0/cqv+kQKDYVokVNgZiXxfqru5gegjcB9QEszawngnFuM949Ib7zQMiLLLtYCvZ1z5bPcop1z67Js47Is34g3RKAnR3+SBa83KhVIx/+H1lcny/JaYOJxbcU45+48wUvM+vy6eD3dW05Sx/E1H267rhXMiX7Ht/0mXs9nQ+dcWbxeRPvNs/LXBrK8D2ZmHBv6jnc6NW7gt+/TiXwK9DSz2njv4Qi/xpLAF8A/8YZalAfG5rKOjTnVYGb1gdfxhulU8vf7Kzl/Vo63Hi9UHt5fGbxhI+tyfEbuHL/fMLz3bB2Ac+4j51wnvKEc4XjHBefcUufc9Xhh8iVgpJlFn2Ytx1sLDDrub7Wkc26GmfXAGx50Dd4vQBXwhqVYluc2yIcaUvCGoR3//6asIff493y9v7yBLMfWX3f4/cqv+kQKDYVokVNzJV7PcRO8sYet8MZaTsY72fCwEXg/TXbFGxN92BvAM2ZWD8DMqpjZFSdorwzeT6pb8YY9/OPwCudNwfZf4AnzTvQ657gavgXONrObzCzSv7U1s8YnaK+fmTUxs1J4vXJf+O3kWIdvE97Y2sNm4v3D+qyZlfZPPOp0gnbzUxlgJ7DXf62/L4A2vwXizewy/4vDvXi/FISixs+AP5lZLTOrhDdGNkfOuU14P5sPA5Y655L8VSWAKLwvYxlmdinecIbc1vCImZU3bx7te7Ksi8ELyql43yduxeuJPmwTUNv8Eymz8TEwyMxa+L/m/BNvqEyOPft5qPly8+ZzjgT+jDcsYoaZNTazHn57+/1bBt4LuMnMKvs91zv915Z5mrUc7w3gr4f/Nv3j2sdfVwbvy/IWvF+GnsDriT7sHeBpM2tgnlaneHLeG8A//PcTM6tq/gmhWTxmZiXNO0H0FrwvaOC9Z38zs8pmVgV4DG+IDnjDOW71j2+YmdW2LCd0ihRFCtEip+YWYJhzbo1zbuPhG96MA32z9Lx+DHTHG6+7Jcvz/wV8A4w1bzaJ6XgnmOXkA7xe7XV4J29NP279PXg9wxvxTvr5GC/s4pzbjffz/PV4PUYbgefwwlNOPsQb37wR7+SiP+ayjneBJv5PwV/5wfsyvLGUa/B6ua47Qbv56QG892k3Xo/vpyfe/PT5QfU6vHGiW/F63n7Bfy/yucbXgR/xfm6fhdebfDIj8H5FOPKriHNuB96vKF/inXDWB+/LQG48jvclKRkYhff5OLzf+cAQjn6ROgfvRLPDfsAbf7vJ/yXnGM650Xhf4L70n18XbxjSaXHOLcI75q/jBfyLgMudc2l4fxPP4wXVjXi9vYfnPL8YWOL/vb4IXOecO3S69RxX2+d4n53P/eE984Fe/urvgXF4xywZ2IV3XA57AfgK7zOxC3gL7283r14GRgM/+q91Gt4JsFlNAVbi/WLxT+fcT/7jT+Kd3LjAr30GR3vyp+GdRDwE70vIeI7t0RYpcswbsicixYmZPYd3gt4tJ91YQsa8KQ7XA32cc5ODrkfkdJhZQyDJORfqYVEiRYJ6okWKAf8EtRb+z7jtgEF4PXhSwMzsIjMr5w8JeAzvJ/iZAZclIiL5TFf1EikeyuAN4aiJN7fuS3jzwkrB64w380UU3jzOV7oz/HLwIiLFkYZziIiIiIjkkYZziIiIiIjkkUK0iIiIiEgeFbkx0ZUrV3axsbFBlyEiIiIixdzs2bO3OOeyne+/yIXo2NhYEhMTgy5DRERERIo5M1ud0zoN5xARERERySOFaBERERGRPFKIFhERERHJoyI3JlpERESksEtLSyMlJYUDBw4EXYrkQnR0NLVr1yYyMjLXz1GIFhEREclnKSkplClThtjYWMws6HLkBJxzbN26lZSUFOLi4nL9PA3nEBEREclnBw4coFKlSgrQRYCZUalSpTz/aqAQLSIiIhICCtBFx6m8VwrRIiIiIsXM1q1badWqFa1ataJ69erUqlXryP1Dhw7lah8DBgxg6dKlJ9zmtddeY/jw4flRMp07d2bu3Ln5sq+CoDHRIiIiIsVMpUqVjgTSJ554gpiYGB588MFjtnHO4ZwjLCz7PtVhw4adtJ2777779IstotQTLSIiInKGWL58Oc2aNeOOO+4gPj6eDRs2cPvtt5OQkEDTpk156qmnjmx7uGc4PT2d8uXL8/DDD9OyZUs6duzI5s2bAXj00UcZPHjwke0ffvhh2rVrR6NGjZg2bRoAe/fu5ZprrqFly5bccMMNJCQknLTH+aOPPqJ58+Y0a9aMRx55BID09HRuuummI48PGTIEgFdeeYUmTZrQsmVL+vXrl+/HLCfqiRYREREJoSf/t4jF63fl6z6b1CzL45c1PaXnLl68mGHDhvHGG28A8Oyzz1KxYkXS09Pp0aMHffr0oUmTJsc8Z+fOnXTr1o1nn32W+++/n6FDh/Lwww//Zt/OOWbOnMk333zDU089xejRo3n11VepXr06I0eOZN68ecTHx5+wvpSUFB599FESExMpV64cPXv25Ntvv6VKlSps2bKFBQsWALBjxw4Ann/+eVavXk1UVNSRxwqCeqJzITPT8eOSTWzfm7sxRCIiIiKFVYMGDWjbtu2R+x9//DHx8fHEx8ezZMkSFi9e/JvnlCxZkt69ewPQpk0bkpOTs9331Vdf/ZttpkyZwvXXXw9Ay5Ytadr0xOF/xowZnHfeeVSuXJnIyEhuvPFGJk2aRMOGDVm6dCn33nsvY8aMoVy5cgA0bdqUfv36MXz48DzN83y61BOdCytS9zDo/UT+clEj7ureMOhyREREpAg51R7jUClduvSR5aSkJP71r38xc+ZMypcvT79+/bKd6i0qKurIcnh4OOnp6dnuu0SJEr/ZxjmXp/py2r5SpUrMnz+fUaNGMWTIEEaOHMlbb73FmDFjmDhxIl9//TVPP/00CxcuJDw8PE9tngr1ROfCWdXK0KlhJT6Ytpq0jMygyxERERHJF7t27aJMmTKULVuWDRs2MGbMmHxvo3Pnznz22WcALFiwINue7qw6dOjA+PHj2bp1K+np6XzyySd069aN1NRUnHP87ne/48knn2TOnDlkZGSQkpLCeeedxwsvvEBqair79u3L99eQHfVE59LATnEMej+R0Qs3clnLmkGXIyIiInLa4uPjadKkCc2aNaN+/fp06tQp39v4wx/+wM0330yLFi2Ij4+nWbNmR4ZiZKd27do89dRTdO/eHeccl112GZdccglz5sxh0KBBOOcwM5577jnS09O58cYb2b17N5mZmTz00EOUKVMm319DdiyvXexBS0hIcImJiQXebmam47yXJlChdBRf3pX/HzAREREpPpYsWULjxo2DLqNQSE9PJz09nejoaJKSkrjwwgtJSkoiIqJw9eVm956Z2WznXEJ22xeu6guxsDCj/7mxPPG/xcxZs534uhWCLklERESk0NuzZw/nn38+6enpOOd48803C12APhVF/xUUoD4JdXhp7DKGTU1WiBYRERHJhfLlyzN79uygy8h3OrEwD2JKRHBd2zqMWrCBDTv3B12OiIiIiAREITqPbjk3lkzn+PDn1UGXIiIiIiIBUYjOozoVS3FBk2qMmLmG/Ycygi5HRERERAKgEH0KBnaKY8e+NL6auy7oUkREREQkAArRp6BdXEWa1izL0Cmr8nwVHhEREZFQ6969+28unDJ48GDuuuuuEz4vJiYGgPXr19OnT58c932y6YYHDx58zEVPLr74Ynbs2JGb0k/oiSee4MUXXzzt/eQHhehTYGYM6BRH0uY9TFm+JehyRERERI5xww038Mknnxzz2CeffMINN9yQq+fXrFmTL7744pTbPz5Ef//995QvX/6U91cYKUSfosta1qByTBRDp6wKuhQRERGRY/Tp04dvv/2WgwcPApCcnMz69evp3LnzkXmb4+Pjad68OV9//fVvnp+cnEyzZs0A2L9/P9dffz0tWrTguuuuY//+ozOU3XnnnSQkJNC0aVMef/xxAIYMGcL69evp0aMHPXr0ACA2NpYtW7yOx5dffplmzZrRrFkzBg8efKS9xo0bc9ttt9G0aVMuvPDCY9rJzty5c+nQoQMtWrTgqquuYvv27Ufab9KkCS1atOD6668HYOLEibRq1YpWrVrRunVrdu/efcrH9jDNE32KSkSE069DPQaPS2Jl6h7qV4kJuiQREREpjEY9DBsX5O8+qzeH3s/muLpSpUq0a9eO0aNHc8UVV/DJJ59w3XXXYWZER0fz5ZdfUrZsWbZs2UKHDh24/PLLMbNs9/X6669TqlQp5s+fz/z584mPjz+y7plnnqFixYpkZGRw/vnnM3/+fP74xz/y8ssvM378eCpXrnzMvmbPns2wYcOYMWMGzjnat29Pt27dqFChAklJSXz88ce8/fbbXHvttYwcOZJ+/frl+BpvvvlmXn31Vbp168bf/vY3nnzySQYPHsyzzz7LqlWrKFGixJEhJC+++CKvvfYanTp1Ys+ePURHR+flaGdLPdGnoW/7ekSFh/HetOSgSxERERE5RtYhHVmHcjjneOSRR2jRogU9e/Zk3bp1bNq0Kcf9TJo06UiYbdGiBS1atDiy7rPPPiM+Pp7WrVuzaNEiFi9efMKapkyZwlVXXUXp0qWJiYnh6quvZvLkyQDExcXRqlUrANq0aUNycnKO+9m5cyc7duygW7duANxyyy1MmjTpSI19+/blo48+OnJlxE6dOnH//fczZMgQduzYkS9XTFRP9GmoUqYEl7WsyRezU3jgwkaUKxkZdEkiIiJS2JygxziUrrzySu6//37mzJnD/v37j/QgDx8+nNTUVGbPnk1kZCSxsbEcOHDghPvKrpd61apVvPjii8yaNYsKFSrQv3//k+7nRBMylChR4shyeHj4SYdz5OS7775j0qRJfPPNN/z9739n0aJFPPzww1xyySV8//33dOjQgXHjxnHOOeec0v4PU0/0aRrQKZZ9hzL4bNbaoEsREREROSImJobu3bszcODAY04o3LlzJ1WrViUyMpLx48ezevWJLyDXtWtXhg8fDsDChQuZP38+ALt27aJ06dKUK1eOTZs2MWrUqCPPKVOmTLbjjrt27cpXX33Fvn372Lt3L19++SVdunTJ82srV64cFSpUONKL/eGHH9KtWzcyMzNZu3YtPXr04Pnnn2fHjh3s2bOHFStW0Lx5cx566CESEhL49ddf89zm8dQTfZqa1SpH+7iKvDctmQGdYokI1/cSERERKRxuuOEGrr766mNm6ujbty+XXXYZCQkJtGrV6qQ9snfeeScDBgygRYsWtGrVinbt2gHQsmVLWrduTdOmTalfvz6dOnU68pzbb7+d3r17U6NGDcaPH3/k8fj4ePr3739kH7feeiutW7c+4dCNnLz//vvccccd7Nu3j/r16zNs2DAyMjLo168fO3fuxDnHfffdR/ny5XnssccYP3484eHhNGnShN69e+e5veNZUZvnOCEhwZ1sbsKCNnrhRu74aDav942nd/MaQZcjIiIiAVuyZAmNGzcOugzJg+zeMzOb7ZxLyG57dZvmgwuaVKN2hZIMnarp7kRERETOBArR+SA8zOh/biyzkrezIGVn0OWIiIiISIgpROeTa9vWoXRUOMPUGy0iIiJS7ClE55Oy0ZH8LqEO/5u/ns27Tjy9i4iIiBR/Re28szPZqbxXCtH56JZzY0nPdHw0Y03QpYiIiEiAoqOj2bp1q4J0EeCcY+vWrXm+iqGmuMtHcZVLc/45VRk+fTV3dW9AdGR40CWJiIhIAGrXrk1KSgqpqalBlyK5EB0dTe3atfP0HIXofDagUxzjlszgm3nruTahTtDliIiISAAiIyOJi4sLugwJIQ3nyGfnNqhEo2plGDpllX7CERERESmmFKLzmZkxsHMsv27czfSV24IuR0RERERCQCE6BK5oVYuKpaN08RURERGRYipkIdrMos1sppnNM7NFZvZkNtuUMLNPzWy5mc0ws9hQ1VOQoiPDubFdXcYt2cTqrXuDLkdERERE8lkoe6IPAuc551oCrYCLzKzDcdsMArY75xoCrwDPhbCeAnVTx3qEm/H+tNVBlyIiIiIi+SxkIdp59vh3I/3b8WfaXQG87y9/AZxvZhaqmgpStbLRXNqiBp8lrmX3gbSgyxERERGRfBTSMdFmFm5mc4HNwA/OuRnHbVILWAvgnEsHdgKVQllTQRrQKY49B9P5PDEl6FJEREREJB+FNEQ75zKcc62A2kA7M2t23CbZ9Tr/Zl44M7vdzBLNLLEoTVresk552tSrwHvTksnI1HR3IiIiIsVFgczO4ZzbAUwALjpuVQpQB8DMIoBywG/mhXPOveWcS3DOJVSpUiXE1eavgZ3iWLNtHz/9ujnoUkREREQkn4Rydo4qZlbeXy4J9AR+PW6zb4Bb/OU+wE+umF2hpFfTatQsF83QKZruTkRERKS4CGVPdA1gvJnNB2bhjYn+1syeMrPL/W3eBSqZ2XLgfuDhENYTiIjwMG4+N5afV25lyYZdQZcjIiIiIvnAilrHb0JCgktMTAy6jDzZse8QHf/5E5e1rMHzfVoGXY6IiIiI5IKZzXbOJWS3TlcsLADlS0VxTZtafDV3PVv2HAy6HBERERE5TQrRBaT/uXEcSs9kxIw1QZciIiIiIqdJIbqANKwaQ7ezq/Dh9NUcSs8MuhwREREROQ0K0QVoYOc4Uncf5LsF64MuRUREREROg0J0Aep6VmUaVo3h3SmrKGondIqIiIjIUQrRBcjM6H9uLAvX7SJx9fagyxERERGRU6QQXcCujq9FuZKRDJuqi6+IiIiIFFUK0QWsVFQEN7Sry+iFG0nZvi/ockRERETkFChEB+DmjvUwMz74eXXQpYiIiIjIKVCIDkDN8iW5qFl1Ppm5hr0H04MuR0RERETySCE6IAM7xbHrQDr/nZMSdCkiIiIikkcK0QGJr1uelnXKM2xqMpmZmu5OREREpChRiA6ImTGwUywrt+xl4rLUoMsRERERkTxQiA5Q72Y1qFa2BEM13Z2IiIhIkaIQHaCoiDBu7hjL5KQtLNu0O+hyRERERCSXFKIDdkO7upSICGPY1OSgSxERERGRXFKIDljF0lFc1boWX/6Swva9h4IuR0RERERyQSG6EBjQKY4DaZl8PGtN0KWIiIiISC4oRBcCjaqXoXPDynwwbTVpGZlBlyMiIiIiJ6EQXUgM6BTLxl0HGLVwY9CliIiIiMhJKEQXEj0aVSW2UimGabo7ERERkUJPIbqQCAszBnSK45c1O5izZnvQ5YiIiIjICShEFyJ92tSmTHSEprsTERERKeQUoguR0iUiuC6hDqMWbGDDzv1BlyMiIiIiOVCILmRuOTeWTOf48OfVQZciIiIiIjlQiC5k6lQsxYVNqjNi5hr2H8oIuhwRERERyYZCdCE0oFMsO/al8eUv64IuRURERESyoRBdCLWLq0jTmmUZNnUVzrmgyxERERGR4yhEF0JmxsBOcSRt3sOU5VuCLkdEREREjqMQXUhd2rIGlWNKMHSKLr4iIiIiUtgoROfWzhTIzCyw5kpEhNOvQ13GL01lZeqeAmtXRERERE5OITo3Ni2CVxNg7kcF2mzf9vWICg/jvWnJBdquiIiIiJyYQnRuVG0CNVvDD3+DvVsLrNkqZUpweauafJ6Yws59aQXWroiIiIicmEJ0bpjBJS/Bwd0w7m8F2vSATrHsT8vg08Q1BdquiIiIiORMITq3qjWBDnfBLx/BmukF1mzTmuVoH1eR96etJj2j4MZki4iIiEjOFKLzottDULY2fHsfZBTc8IqBneNYt2M/PyzeVGBtioiIiEjOFKLzokQM9H4ONi+G6a8XWLM9G1ejTsWSDJ2q6e5ERERECgOF6Lw65xI4+yKY8Kw37V0BCA8zbukYy6zk7SxI2VkgbYqIiIhIzhSi88oMej8PLhNGPVRgzV7btg6lo8IZpt5oERERkcApRJ+KCvWg25/h129h2ZgCabJsdCS/S6jD/+avZ/OuAwXSpoiIiIhkTyH6VHX8A1RuBN8/CIf2FUiT/c+NJT3T8dH01QXSnoiIiIhkTyH6VEVEeXNH71gDk18skCZjK5fm/HOqMnzGGg6kZRRImyIiIiLyWwrRpyOuC7S4HqYOgdSlBdLkwE5xbN17iG/mrS+Q9kRERETktxSiT9eFT0NUKfjuAXAu5M11bFCJc6qXYeiUVbgCaE9EREREfksh+nTFVIHzH4fkyTD/s5A3Z2YM6BTLrxt3M33ltj41oaAAACAASURBVJC3JyIiIiK/pRCdH9oMgFptYOxfYf/2kDd3RataVCwdpYuviIiIiAREITo/hIXBpa/Avq3w499D3lx0ZDh929dl3JJNrN66N+TtiYiIiMixFKLzS42W0O52SBwKKbND3ly/DvWICDPem5Yc8rZERERE5FgK0fmpx18hphp8dx9khnYKumplo7mkeQ0+T0xh94G0kLYlIiIiIsdSiM5P0WXhon/Ahnkw652QNzewcxx7DqbzeWJKyNsSERERkaMUovNb06uhfg/46WnYvTGkTbWoXZ6EehV4b1oyGZma7k5ERESkoChE5zcz70qG6QdhzCMhb25ApzjWbNvHT79uDnlbIiIiIuJRiA6FSg2g832wcCSs+CmkTfVqWo2a5aIZOkXT3YmIiIgUFIXoUOl8H1SsD989CGkHQtZMRHgYt5wby88rt7J4/a6QtSMiIiIiRylEh0pkNFz8ImxbAVP/FdKmrm9bl5KR4QzTxVdERERECoRCdCg1PB+aXgWTX4KtK0LWTLlSkVzTphZfz1vPlj0HQ9aOiIiIiHgUokOt1z8hPAq+/zO40M2g0f/cOA6lZzJixpqQtSEiIiIiHoXoUCtbA877K6z4ERZ/FbJmGlaNoXujKnw4fTWH0jND1o6IiIiIKEQXjLa3QfXmMPr/4EDoTv4b0CmO1N0H+W7B+pC1ISIiIiIhDNFmVsfMxpvZEjNbZGb3ZrNNdzPbaWZz/dvfQlVPoMIj4NLB3sVXJvwzZM10PasyDavG8O6UVbgQDh0REREROdOFsic6HXjAOdcY6ADcbWZNstlusnOulX97KoT1BKt2ArTpDzPegA3zQ9KEmTGgUywL1+0icfX2kLQhIiIiIiEM0c65Dc65Of7ybmAJUCtU7RUJPR+HkhXhu/shMzTjlq9uXZtyJSN5Y8IK9UaLiIiIhEiBjIk2s1igNTAjm9UdzWyemY0ys6Y5PP92M0s0s8TU1NQQVhpiJSvAhU9DyiyY835omogK5/fd6vPjr5t5dtSvCtIiIiIiIRDyEG1mMcBI4E/OuePPqpsD1HPOtQReBbKdvsI595ZzLsE5l1ClSpXQFhxqLa+Hep1h3BOwJzRfCO7s1oB+Hery5qSV/OvHpJC0ISIiInImC2mINrNIvAA93Dn33+PXO+d2Oef2+MvfA5FmVjmUNQXODC55CQ7tgR9Ccx6lmfHU5c24Jr42g8cl8ebE0F3oRURERORMFMrZOQx4F1jinHs5h22q+9thZu38eraGqqZCo+o5cO4fYN4ISJ4akibCwozn+7Tg0hY1+OeoX/ng5+SQtCMiIiJyJooI4b47ATcBC8xsrv/YI0BdAOfcG0Af4E4zSwf2A9e7M2UQb9e/wIKR3kmGv58MEVH53kR4mPHKda04kJbJ375eRHREONe2rZPv7YiIiIicaayoZdaEhASXmJgYdBn5Y+ko+Ph66PkEdL4vZM0cSMvgtg8SmbJ8C4Ova8UVrc7sSVJEREREcsPMZjvnErJbpysWBqlRb2h0CUx8HnasCVkz0ZHhvHVTAm1jK3L/Z/MYvXBjyNoSERERORMoRAet93Pef0c9FNJmSkaFM7R/W5rXKscfPp7DhKWbQ9qeiIiISHGmEB208nWg20Ow9Hv49fuQNhVTIoL3B7bjrKpl+P2Hs5m2YktI2xMREREprhSiC4OOd0OVxjDqL3Bob0ibKlcykg8HtaNuxVLc+n4is1dvC2l7IiIiIsWRQnRhEB4Jl74MO9d646NDrFJMCYbf2p6qZUrQf+gsFqTsDHmbIiIiIsWJQnRhUe9caNUXfv43bF4S8uaqlo1m+G0dKFsykpuGzmDpxt0hb1NERESkuFCILkwueAqiYuC7B6AAph6sVb4kI25rT1R4GH3fmcHK1D0hb1NERESkOFCILkxKV4YLnoTVU2HexwXSZL1KpRlxW3ucc/R9ZwZrt+0rkHZFREREijKF6MKm9c1Qux2MfRT2FcxJfw2rluHDQe3ZdyiDG9+Zzoad+wukXREREZGiSiG6sAkL804y3L8DfnyywJptUrMsHwxsx/a9afR9ewapuw8WWNsiIiIiRY1CdGFUvTm0vwNmvwdrZxVYsy3rlGfYgLZs2HmAm96dwfa9hwqsbREREZGiRCG6sOrxf1CmJnx7H2SkF1izbWMr8vbNCazcspebh85k14G0AmtbREREpKhQiC6sSpSBi/4JmxbAzLcKtOnOZ1XmjX7xLNmwiwHDZrH3YMGFeBEREZGiQCG6MGtyBTTsCeOfgV3rC7Tp886pxpAbWvPLmu3c+n4iB9IyCrR9ERERkcJMIbowM4OLX4DMdBj9fwXe/MXNa/DStS2Zvmord3w0m4PpCtIiIiIioBBd+FWsD10egMVfwfJxBd78Va1r88yVzZmwNJU/fvwL6RmZBV6DiIiISGGjEF0UdLoXKjWE7x6EtIKfw/nG9nX526VNGLNoEw98Po+MzNBfTVFERESkMFOILgoiSsAlL8H2VTDllUBKGNg5jj/3asTXc9fz1y8XkKkgLSIiImewiKALkFyq3x2a9fFCdPNroXLDAi/h7h4NOZCWwas/LSc6MpzHL2uCmRV4HSIiIiJBU090UdLrHxARDd8/AC6YnuD7LzibQZ3jeG9aMs+NXooLqA4RERGRIClEFyVlqsF5j8HKCbBwZCAlmBmPXtKYvu3r8sbEFbz60/JA6hAREREJkkJ0UdN2ENRoBWMegQM7AynBzPj7Fc24Or4WL/+wjLcmrQikDhEREZGgKEQXNWHhcOkrsGcz/PRMcGWEGc9f04JLWtTgH9//yoc/JwdWi4iIiEhBU4guimrFez3Ss96G9XMDKyMiPIzB17WiZ+OqPPb1Ij5LXBtYLSIiIiIFSSG6qDrvMShVGb69DzKDu5JgZHgY/74xni5nVebhkfP5Zl7BXp5cREREJAgK0UVVyfLQ6xlYPwdmDwu0lOjIcN66KYGE2Irc9+lcxizaGGg9IiIiIqGmEF2UNf8dxHWFcU95Y6QDVDIqnKH929KsVjn+MOIXJi5LDbQeERERkVBSiC7KzODilyBtH4x9NOhqiCkRwQcD2tGwagy3f5DIzyu2Bl2SiIiISEgoRBd1Vc6GTvfC/E9h1aSgq6FcqUg+HNSOOhVLMej9WcxevT3okkRERETynUJ0cdD1QShfD757ANIPBV0NlWJKMOLW9lQtU4L+w2aycF0w81mLiIiIhIpCdHEQWRIufhG2LINpQ4KuBoCqZaMZflsHykZHctO7M1i2aXfQJYmIiIjkG4Xo4uLsC6HxZTDpBdieHHQ1ANQqX5Lht7YnMjyMG9+ewcrUPUGXJCIiIpIvFKKLk4ueBQuH7/8CzgVdDQCxlUsz4rb2OOfo+84M1m7bF3RJIiIiIqdNIbo4KVcbevwfJI2BX78NupojGlYtw4eD2rP3YDo3vjOdjTsPBF2SiIiIyGnJVYg2swZmVsJf7m5mfzSz8qEtTU5J+zugalP4+h749bugqzmiSc2yfDCoPdv3pnHjO9NJ3X0w6JJERERETllue6JHAhlm1hB4F4gDRoSsKjl14ZFw/XCoUA8+udEb2pFeOAJrqzrlGdq/Let37Oemd2ewY1/wM4mIiIiInIrchuhM51w6cBUw2Dl3H1AjdGXJaakYB4N+gA53wcw34Z2esGV50FUB0C6uIu/c3JaVW/Zy89CZ7DqQFnRJIiIiInmW2xCdZmY3ALcAhwfbRoamJMkXESXgon/CDZ/AzrXwZleY90nQVQHQ+azKvN43nsXrdzFw2Cz2HUoPuiQRERGRPMltiB4AdASecc6tMrM44KPQlSX5plFvuGMq1GwFX/4evrwDDgY/1dz5javxr+tbM2fNdm59P1FBWkRERIoUc3mcCs3MKgB1nHPzQ1PSiSUkJLjExMQgmi7aMjNg4vMw6XmoWB/6DIMaLYKuiv/OSeGBz+dRr2IpXvxdSxJiKwZdkoiIiAgAZjbbOZeQ3brczs4xwczKmllFYB4wzMxezs8iJcTCwr3p727+Bg7thXfOhxlvBT6f9NXxtRlxawfSMx2/e/NnnvluMQfSMgKtSURERORkcjuco5xzbhdwNTDMOdcG6Bm6siRk4rp4wzvq94BRf4ZP+sK+bYGW1LFBJUb/qSs3tqvL25NXccmQyfyyZnugNYmIiIicSG5DdISZ1QCu5eiJhVJUla4EN34Kvf4JSWPhjS6w+udAS4opEcEzVzXnw0Ht2H8og2ten8bzo3/lYLp6pUVERKTwyW2IfgoYA6xwzs0ys/pAUujKkpAzg453waCx3tzS710ME1/wxk4HqMtZVRh9X1d+16YO/5mwgstencKClJ2B1iQiIiJyvDyfWBg0nVgYAgd2wbf3wcIvIK4rXPUWlA1+GvDxSzfz8Mj5bNlziLt7NOSeHg2JitCV6kVERKRg5MeJhbXN7Esz22xmm8xspJnVzt8yJTDRZeGad+CK1yAlEd7oDEk/BF0VPRpVZeyfunFFq5oM+TGJK1+byuL1u4IuS0RERCTXwzmGAd8ANYFawP/8x6S4MIPW/eD2CRBTDYb3gbGPQnqwl+YuVyqSl69txds3J7B590GueG0Kr/6YRFpGZqB1iYiIyJkttyG6inNumHMu3b+9B1QJYV0SlCqN4LYfIWEQTHsVhl0E21YFXRUXNKnGD/d1pXezGrz0wzKu/s80lm3aHXRZIiIicobKbYjeYmb9zCzcv/UDtoayMAlQZEm49GW49gPYsty7ZPjCkUFXRYXSUQy5oTWv941n3Y79XDpkCq9PWEG6eqVFRESkgOU2RA/Em95uI7AB6IN3KXApzppcAXdMhirnwBcD4Zs/wqF9QVdF7+Y1GHtfV85vXJXnRv9Knzd+ZkVq8JcyFxERkTNHrkK0c26Nc+5y51wV51xV59yVeBdekeKuQj0Y8D10vh/mfABv94BNi4OuisoxJfhP33hevaE1yVv3cvG/JvPO5JVkZBat2WZERESkaDqd+cLuz7cqpHALj4Sej8NN/4V9W70gPfu9wC8ZbmZc1rImY+/rSpezqvD0d0u4/q2fSd6yN9C6REREpPg7nRBt+VaFFA0NzvMuGV63I/zvXvhiABwI/kIoVctE8/bNbXj52pYs3bibi/41ifemriJTvdIiIiISIqcTopVQzkRlqkG//0LPJ2DxN96c0inBX/zGzLg6vjZj7+tGh/qVeOJ/i7nxnems3Rb8GG4REREpfk4Yos1st5ntyua2G2/OaDkThYVB5/tg4Gjvq9TQXjD1X5AZ/CwZ1ctFM6x/W56/pgWL1u2i1+BJfDR9NUXtypwiIiJSuOmy33J69u+Ab/4AS76Bhj3hyjcgpnBMIb5ux34eHjmfyUlb6NywMs/1aUGt8iWDLktERESKiNO+7LdIjkqW9+aTvuRlWDUZ3ugEKycEXRUAtcqX5IOB7XjmqmbMWbOdXq9M4tNZa9QrLSIiIqdNIVpOnxm0HQS3j4fo8vDBlfDj3yEjPejKMDP6tq/HmD91pVmtsjw0cgED3pvFxp0Hgi5NREREijCFaMk/1Zp6Qbp1P5j8Irx3CexYG3RVANSpWIoRt3bgycubMmPlNi54ZSIjZ6eoV1pEREROSchCtJnVMbPxZrbEzBaZ2b3ZbGNmNsTMlpvZfDOLD1U9UkCiSsMV/4Zr3oVNi7zZO5Z8G3RVAISFGbecG8uoe7twTvUyPPD5PG77YDabd6tXWkRERPImlD3R6cADzrnGQAfgbjNrctw2vYGz/NvtwOshrEcKUvM+8PuJUCEWPu0L3/8Z0gpHWI2tXJpPbu/Io5c0ZnJSKhe+Momv565Tr7SIiIjkWshCtHNug3Nujr+8G1gC1DpusyuAD5xnOlDezGqEqiYpYJUawKAfoOM9MPMteKcnbEkKuioAwsOMW7vU5/t7uxBXuTT3fjKXu4bPYcueg0GXJiIiIkVAgYyJNrNYoDUw47hVtYCsg2ZT+G3QxsxuN7NEM0tMTU0NVZkSChFR0OsZuPEz2LUO3uwGc0cEXdURDarE8MUd5/Jw73P4cclmLnxlEt8v2BB0WSIiIlLIhTxEm1kMMBL4k3Nu1/Grs3nKb35Td8695ZxLcM4lVKlSOOYgljw6uxfcORVqtoav7oT//h4O7g66KsDrlb6jWwO++2NnalcoyV3D5/CHj39h+95DQZcmIiIihVRIQ7SZReIF6OHOuf9ms0kKUCfL/drA+lDWJAEqWxNu+Qa6PwILPvN6pdfPDbqqI86qVob/3nkuD154NqMXbuCCVybxw+JNQZclIiIihVAoZ+cw4F1giXPu5Rw2+wa42Z+lowOw0zmn39KLs7Bw6P4Q3PItpO2Hdy+A6W9AITmpLyI8jHvOO4tv7ulM1TIluO2DRO7/dC4796UFXZqIiIgUIiG77LeZdQYmAwuATP/hR4C6AM65N/yg/W/gImAfMMA5d8Jreuuy38XIvm3w1V2wbBTUbgu9/gl12gZd1RGH0jN5bfxyXhu/nEoxUTx7dQt6nFM16LJERESkgJzost8hC9GhohBdzDjnnWj441OwZyM0uwZ6PgHl6wZd2REL1+3kgc/msXTTbq5NqM2jlzahbHRk0GWJiIhIiClES+F3cA9MGwJTh4DLhI53Q5f7oUSZoCsD4GB6BkN+TOL1CSuoWLoEfzivITe0q0tUhC76KSIiUlwpREvRsTMFfvw7zP8ESleF8x71LiMeFh50ZQDMT9nBM98tYcaqbdSuUJI/9Tybq1rXIjwsu4lmREREpChTiJaiZ91sGPNXWPMzVG3qzTXdoEfQVQHgnGNy0hZeGLOUBet20rBqDA9eeDa9mlbHG+YvIiIixYFCtBRNzsHir+GHv8GO1XD2RXDB36HK2UFXBnhhevTCjbw4dikrUvfSonY5/tyrEZ0bVlaYFhERKQYUoqVoSzsAM9+ESS9C2j5IGATdH4ZSFYOuDID0jEy+/GUdg8clsW7HfjrUr8hfLjqH+LoVgi5NREREToNCtBQPe7fA+H/A7GHeCYfdHoK2t3mXFi8EDqZn8PGMNfx7/HK27DlEz8bVeLDX2ZxTvWzQpYmIiMgpUIiW4mXzEhj7KCwfBxXre0M8zrkECskQin2H0hk2NZk3Jq5gz8F0Lm9Zk/svOJt6lUoHXZqIiIjkgUK0FE9J42DsXyH1V4jt4p18WKNl0FUdsXNfGm9OWsGwqcmkZWRybds6/PG8s6heLjro0kRERCQXFKKl+MpIhznvecM89m2DVjfCeY9B2RpBV3bE5t0HeO2n5YyYuYYwM245N5Y7uzWgQunCMQxFREREsqcQLcXfgZ3eiYcz3oCwSOj8J+h4D0SVCrqyI9Zu28fgcUl8+UsKpaIiuK1LfQZ1iSOmRETQpYmIiEg2FKLlzLFtFYx73Jsar2wtOP9xaP47CCs8VxZM2rSbl8YuY/SijVQsHcVd3RvQr0M9oiMLxwVlRERExKMQLWee1T/DmP+D9b9AzXjo9Q+o1zHoqo4xb+0OXhy7lMlJW6hRLpp7zz+LPm1qExFeeAK/iIjImUwhWs5MmZmw4DMY9yTsXg9NroCeT0LFuKArO8a0Fd7VD39Zs4O4yqW5/4KzuaR5DcJ0KXEREZFAKUTLme3QPpj2KkwdDJnp0P4O6PogRJcLurIjnHOMW7KZF8csZemm3TSpUZY/92pE90ZVdPVDERGRgChEiwDs2gA//R3mjvCudtjjEYjvD+GF58S+jEzHt/PX8/IPy1i9dR9tYyvw517n0C6ucFydUURE5EyiEC2S1fq5MOavsHoKVDkHLnwGzuoZdFXHSMvI5LPEtQz5MYlNuw7S7ewq/LlXI5rVKjy95yIiIsWdQrTI8ZyDX7+DHx6DbSuhYU+48Gmo2jjoyo5xIC2DD35O5j8TVrBjXxqXNK/B/ReeTYMqMUGXJiIiUuwpRIvkJP0QzHobJj4HB/dAm/7eMI/SlYOu7Bi7DqTxzuRVvDt5JfvTMujTpjb39jybWuVLBl2aiIhIsaUQLXIye7fCxGdh1rsQVdo78bD9HRBRIujKjrF1z0H+M2EFH05fDQ76dqjL3T0aUjmmcNUpIiJSHChEi+RW6jIY+ygkjYHy9eCCp7yp8QrZDBnrd+xnyI9JfD47hRIRYQzqHMetXepTrmRk0KWJiIgUGwrRInm14icY8yhsXgR1O0KvZ6BWm6Cr+o2VqXt4+YdlfDt/A+VKRnJHtwb0PzeWklG6+qGIiMjpUogWORWZGTDnAxj/DOxNhRbXw/l/g3K1gq7sNxau28lLY5cyfmkqVcuU4A/nn8V1CXWIitDVD0VERE6VQrTI6TiwC6a8Aj+/BhYGCQOg8WVQu12hmmMaYFbyNl4YvZSZyduoU7Ek9/U8myta1SJcVz8UERHJM4VokfywfTX8+BQs/hoy06BkBTjrQmjUGxqcD9Flg64Q8K5+OHFZKi+MWcqi9buIq1yaO7s14MrWtdQzLSIikgcK0SL56cBOWP4jLBsNSWNh/3YIi4TYTnB2b2h0EVSIDbpKMjMdYxdv5N/jl7Nw3S5qlovm9q71ub5dXaIjNWZaRETkZBSiRUIlIx1SZsLSUV6o3rLMe7xqEzj7Iq+XulYbCAsutB7umX5t/HJmJW+nckwUgzrXp1+HupSJ1mweIiIiOVGIFikoW1ccDdSrp4HLgFKV4exeXqCu3wNKBHe1wRkrt/LahBVMWpZK2egI+neKY8C5sVQoHRVYTSIiIoWVQrRIEPZv94Z9LP0eksbBwZ0QHgVxXY/2UperHUhp81N28Nr45YxZtIlSUeH0bV+X27rUp2rZ6EDqERERKYwUokWClpEGa36GpaO9UL19lfd49eZHx1HXaA1hBXvi37JNu/nP+OV8M289EeFhXJtQm993bUCdiqUKtA4REZHCSCFapDBxzhs7fXjYx9oZ4DIhppo/7ONiiOsGUQUXZFdv3csbE1fwxewUMh1c2aoWd3ZvQMOqwQ09ERERCZpCtEhhtncrLP/B66Fe/hMc2g0R0VC/uzfs4+yLoGyNAillw879vD1pFSNmruZgeia9m1Xn7h4NaVqzXIG0LyIiUpgoRIsUFemHYPUUb9jHslGwY433eM3WR4d9VG8BFtqLp2zdc5ChU1fxwbTV7D6YTo9GVbjnvIa0qVcxpO2KiIgUJgrRIkWRc7B58dFhHymJgIOytY6emBjbBSJDdzLgzv1pfPhzMkOnJrNt7yE61K/IPT3OolPDSliIg7yIiEjQFKJFioM9m72LuywdBSt+grR9EFkaGvTwh330gpiqIWl636F0Pp65lrcmrWDTroO0rFOeu7s3oGfjaoTpkuIiIlJMKUSLFDdpByB58tFe6l3rAIPaCUd7qas2yfdhHwfTMxg5ex1vTFzBmm37aFStDHf1aMClLWoSrjAtIiLFjEK0SHHmHGycf3Qc9fpfvMfL1/UC9VkXQmxniCyZb02mZ2Tyv/nr+c/4FSRt3kNspVLc2b0BV7WuTVREwU7TJyIiEioK0SJnkl0bIGmM10u9cgKkH/Bm+6jXCRr29G6Vz8qXXurMTMfYxZt4bfxyFqzbSY1y0dzetT7Xt61LyajgLnUuIiKSHxSiRc5Uafth9VTvyolJP8DWJO/x8nWPBuq4rlCizGk145xjUtIWXvtpOTOTt1E5JoqBneO4qUM9ykRH5sMLERERKXgK0SLi2Z7sBerlP8KqiXBoD4RFQt0OR0N1taan1Us9c9U2/j1+OZOWpVI2OoL+58YyoFMcFUpH5d/rEBERKQAK0SLyW+mHYO10WD7OC9WbFnqPl6kBDc6Hs3p6F3wpWeGUdj8/ZQf/Gb+C0Ys2UioqnL7t63Jrl/pUKxu6KflERETyk0K0iJzcrvV+L/U4WDkeDuwEC4PabY/2UtdoBWF5O3EwadNu/jNhBd/MW0+4Gb9LqM0d3RpQp2LBXdZcRETkVChEi0jeZKTDukS/l3rc0Rk/SlXyeqkb9oSG50Ppyrne5Zqt+3h94gpGzk4hwzmuaFWTu7o3pGHVmBC9CBERkdOjEC0ip2dPqneBl+XjYMWPsG8rYFCzlR+oL4BabSA84qS72rjzAG9NWsmImas5mJ5J72bVuat7Q5rVKhf61yEiIpIHCtEikn8yM2HDXH/oxw+QMgtcJkSXg/o9jg79KFvjhLvZuucgw6Ym8/60ZHYfTKd7oyrc3LEeCbEVKasZPUREpBBQiBaR0Nm/3ZuP+vAJirs3eI9Xa+YN+WjYE+p0gIjsZ+fYdSCND39ezbtTVrFt7yHMoFG1MrSpV4GE2Aok1KtI7QolsXy++qKIiMjJKESLSMFwDjYtOjqWes10yEyDqBiI63Y0VFeo95unHkjLYM7q7ST6tzmrt7PnYDoA1cqWIKFexSPBukmNskSE68qI/9/encfGmd/3HX9/Z4ZDckjOwUu8ydWxq2uti3L2dOy4CWzHsAv0j8RNWyMJYMBIGvdImwQBGqAoihS9EtdBDDdxHaOOk8CxEdepHTtrI5ut9xDXq3OlXWklUrwkkiI5PEQOj/n1j+fhcHhJopfDhxx+XsCDeeZ5nhn95lkt56Mfv7/fT0RECkshWkSCkZmEWy96gfr630L6tne89vHlwYntz667JPli1vHWnUle7xn1gnX3GP3jMwCUl4Q51Zaksz3FmY5qTrUlVQIiIiJbTiFaRILnHIxcX+6l7n4JFjMQKYeO5/zVE5+H2ic2HKA4mJ6hq3uM13vG6OoZ5c2BCbKOXAnI2Y5qOjtSnGlP0ZxUCYiIiLw7CtEisvPM3feXJPdD9b0b3vFIOTQ86c380XjSe9wgWE9nFjjfO8657lFe7xnjjdvjuRKQhngZZzpSdLanONtRzeGGKpWAiIjIpihEi8jON3oLel/z5qQePA+DF2F+2jsXKYeG48uhuvEk1B1eE6wXs45rdyZ4vWeMc91jvN49ykB6FoBY1CsBOdNe/7WUswAAG91JREFUTWd7ilNtSapUAiIiIg+gEC0iu0920eudHjjvheqB83DnIsxNeecjZd4MIE0noenUhsF6YHyGrh4vUHf1jHF10CsBCRkcbojnyj86O6ppTq6tzRYRkb1LIVpEikM26wXrpVA9eB4GL6wfrJd6resOQ3i5x3kqs8Abt8dytdVv3B5jem4RgMZEGWf88o8z7SmVgIiI7HEK0SJSvLJZGH3HC9X5pSBzk975cOnaUpD6I7lgvbCY5dqdSbr8nurXe8YY9EtAKqJhTrWlcsH6ZFuSytKHr8ooIiLFQSFaRPaW/GCd67W+sDJY7zu2sse6/mguWPePz9DlD1Y81z3GW3eWS0CONMbp9Ms/nj5QQ21laYAfVERECkkhWkQkm4XRm36ofsML1YMXIDPhnQ9H1ykFOQKRKJOz87xxe9zvqR7ljdvj3PdLQI40xnn+UC3PHqzlvR3VlEfDAX5IERHZSgrRIiLryWZh7NZyGciAXwqSSXvnw1Gvx3pFKchRFizClYEJXroxwkvXR3i9Z4y5xSzRSIjO9hTPHarl+YN1HGuKEwpprmoRkd1KIVpE5FE9SrCuPwqNJyDVAYkWMrEm3pio4Af9Yf7unXGu3fHKRpKxEp49UMtzh2p57mAtrdWx4D6XiIhsmkK0iMi7sRSs82cFuXMZZkZXXWhQ1cB8ZRNDVsv1TJIfjVfw1kyCAVdDONXCsYMHeP7xOp4+UEuiXPNUi4jsZIGEaDP7IvBRYMg5d3yd8+8H/gq45R/6unPu3z/sfRWiRWTHyEzBRD+k+7xtvf2F2ZUvcSUMumoGqGG2vJHy2nb2tR6g9bHHKUm1QqIFSqsC+kAiIpLvQSG6kHM1fQn4HPDlB1zz9865jxawDSIihVNaCXVPeNt6nIP7o5DuzYXqyHgvVYO3aL93m9LpC6T6vk+438Eryy9bjMYJJVuwRIsXquPNkGiFRLP3vKoJItHt+YwiIrKugoVo59yLZtZRqPcXEdnxzKCixtuaTgIQBmryLpm4P8P5K1d5++1r3Ll9g/DUAE0LI3TMj3MgfZM69xqlc+Or3xgq69cP2HE/eFfUQUgLxYiIFErQqwY8bWYXgAHg151zVwJuj4jItorHynnf2dO87+xpwJuj+qXrw3ztxj3+340RRqfnKCPDM7UzfKBxns7UNAeiaaLT/ZDuh6GrcONvYf7+yjcORyHetByqU+1QcxBqDkD1AShPBvBpRUSKR0EHFvo90d/aoCY6DmSdc1Nm9hHg951zhzZ4n08BnwJoa2s709PTU7A2i4jsFNms483B5an0XuseZW4hS0nYONWW4vmD3swf72lOEM6Mr6rH7vVC9lJt9kQ/uOzym1fULYfqmoPLW+oxKCkL7kOLiOwggc3O8aAQvc613UCnc27kQddpYKGI7FWz84t0dY/x9zeGeen6CFcGvIVi4mURnj5Qw3OH6nj+YC3tNTHMVs1PvZCBsW64dyNve8d7nLqbd6FBstXrrc4P1zUHINkGIS0mIyJ7R1ADCx/IzBqAu845Z2bvBULAvaDaIyKy05WVhL05pw/Vwofh3lSGH75zj5euj/DSjRH+5ooXhltS5blVFJ89UEuqIgqR0o0HQc5OeMukL4Xqpe3iny+v6AheiUjqsfV7sCvrvRpwEZE9opBT3H0VeD9QC9wFfgcoAXDOfd7MfhX4NLAAzAD/yjn3w4e9r3qiRUTWcs5xa2Q6V/rx8jv3mMwsYAbHmxI8c7CGp/fX0NlRTWXpI/afOAfTw+v3Xo/ehMW55WujVWuDdc0BbytLFOZDi4gUmBZbERHZYxYWs1zoS/u91MOc7x1nftERDhnvaUnw1P6lUJ0iFv0xfimZXfRqrfOD9dI2fhvI+26pqF+/97r6Ma+HXERkh1KIFhHZ4+7PLfB6zxiv3LzHy+/c42JfmoWsIxIyTrQmeWp/NU/vr+VMe4ry6Luse56f3bj+enoo70Lz6qxX91xX74eyJEQrvBISlYmISEAUokVEZIXpjBeqX755j1dueqF6MesoCRsnW5O5nurT7SnKSrZwMOFs2g/U76wN2XOTa68PRbwwHa30H5f2Vz+v2OC5v1+a95pImYK5iDwShWgREXmgqcwCXd2jfqge5VLfOFkH0XCIk23LofpUW3JrQ/US52BqyBvgOHoL5qb8bdpbXn1uevn5mn3/OY/4fWahhwTv1UH9IYG9PKmyFJEipRAtIiKbMjk7T1f3ck/15f60F6ojIU7nheqTbUlKIztg2jvnYH4mL2CvF7wfEMQzU+tf6xYf7c8vS0DlPq/+uzJvq6j3jlfW+efrIFxS2HshIltGIVpERN6V9Mw8Xd2jXk31zXtcGZjAOSiNhDjdluLpAzU8tb+GE62JnRGqt4Jz3vzaG4bvKchMwsy4V+s9dRemhr3H6eGV0wPmK6/eOGTnH4vVQDjohYVF9jaFaBER2VLpmXleuzWaG6h49Y4XqstKQpxpT/H0fi9Uv6clSTQSCrq5wZif8UpUpobWCdlDy+emhmB+ep03MKiofYTe7XovcIf26H0WKSCFaBERKajx+3O8mheqr93xBgmWl4Tp7EjxVC5UJygJK+ytkZlaFaz93uz1gvfC7NrXW9gL3BuF7FwI3wflKQ2sFHlECtEiIrKtxqbnePWWN0jxlZvLoToWDdPZUe1PqVfDk80JIgrVj845r4TkUXq3p4dWLoizpKQCEi3LW7IVEktbC8SbVLct4lOIFhGRQN2byvDardHcQMW3704BUBENc/ax6txAxWNNcYXqreIczI6vDNmTdyDdD+nb3mI56T6vxzufhaCq0Q/ZrXlhu235WFk8mM8kss0UokVEZEcZmcrw6s1RXr45wis3R7kx5IXqqtIInR0pTrelONGa5ERrkkS5ekULan5mZbAe7/UDdq+/9UN2fuVrShN5vdj5YbvVO1a5D0JFMsBU9jSFaBER2dGGJmd51S/9ePXWcqgG2F9XwcmWJCfbkpxoSXKkMb53BysGIZv1erJXBOtVYXt2fOVrQhGINy+H6xVh29+PxoL5PCKboBAtIiK7ysTsPJf60pzvHc9tw5MZwFsA5mhTnJOtydzWXhPDNFguOLMTMNHvB+v8nmw/bE8OgMuufE2sZm2wzoXtNm+gpP6bSsAUokVEZFdzzjGYnl0Rqi/1pZmZ9xZDScZKONGyHKpPtCaprogG3GrJWVyAycG8YJ1Xk53u9YL26mn+ImVQ1QCVDVC1z59xZJ9/LO95Ra1KR6RgFKJFRKToLCxmuT40xfnecS74wfrtu5Nk/a+1tupYLlCfbE1yrClemCXL5d1zDmbGVgXr295AyKm73jZ5FzLpta+1sLcSZGX9yoC9Yt9/LCnf/s8mu5pCtIiI7AnTmQUu9adzofp87ziDaW9e5UjIONIYXxGs99dWEAqpZGDXmJ9ZDtS5cH1n1b4/vd/q8hHwBkSu6dWu93q780O45tIWn0K0iIjsWXcnZlf0Vl/sSzOVWQCgqizCiZYkJ1oTnGxNcbI1SV1VacAtlnctuwjTI8vhek3YvgtTd7zHhZm1rw9HV5aMVO1bFbTzgrfm1C5qCtEiIiK+bNbxzvBUrqf6Qt841wYnWfDrQJqT5X5vtResjzfHiUUjAbdaCiK3eM2qnuylgJ1/fGZ0/feI1XiBuqLWC9+hCIQj3mMoAqESr2Y7XJJ3LG8L++dDeed/rNdHlt9jvdfnro2ohnwTFKJFREQeYHZ+kcv96RXBunfU66EMh4zH91VxsjXhD1xMcbC+krDKQPaWhTl/wZqlcO0H7qUe7ukRbz7t7ILXE764tJ+3Lc5757ILy9cGwrySldUL6uQ/r9wHIU0lqRAtIiKySSNTGS72jXP+9jjn+7w66/SMt+hIRTTMky0JTrQmOd2WorM9RU2lykBkk5zzardzgTsvZC/mBfKlwL1eCF8R2B/y+uyCN1NKdt4L/fkDOeemVrYtVOItAb9RyE60QGllMPdtGylEi4iIvEvOOW6NTHMhL1hfHZhgbtEbwLa/roLO9hSdHdWc7aimQ3NXy27hHMyml0P1RF9ewF46NgBuceXrypLrhOy8oF3VsOtLRxSiRURECiCz4JWBnOseo6t7jK6eUcbve73VtZVROtur6ezwgvWxpjglYf16XHapxQWvhCW/93pF0O71gng+C/srV24QshMtUBYP5vM8IoVoERGRbZDNOm6OTHGue4xz3aN0dY9xe/Q+AOUlYU62Jjnrh+pTbUmqyjSzgxSRpZUrNwrZEwNr68BLEw8O2VWN3kDJgChEi4iIBGRoYpaunuVQfWUgTdZByOBwQzwXqs92VNOQKAu6uSKFk130BmFuFLLTfd6iO/ksBFVN8EvfhmTbtjdZIVpERGSHmMoscP72uBeqe0Z54/Y49+e8WtOWVDlnO6o5057ibEc1h+ortRiM7C2ZKb83e1XI/tn/CtGKbW+OQrSIiMgOtbCY5ergZC5Un+seY3gyA0C8LEJnh1dXfbajmiebE1q6XGQbKUSLiIjsEs45bo/ezw1UPNc9xo0hb/qxaDjEky0JL1S3ez3WqYpowC0WKV4K0SIiIrvY6PQcr/eM0dU9yrnuUS71p5lf9L6/D9VXejOAtHt11a3V5ZpaT2SLKESLiIgUkdn5RS70jtPlB+uunjEmZ71ZD+qrSjnrl4B0tldzpLGKiKbWE/mxPChEBzdniIiIiPxYykrC/MT+Gn5ifw3gTa339tCkP1+1NwvIX18aBCAWDXurKvqh+nhznGRMJSAi75Z6okVERIrQwPhMrqf6XPcY1+5MsPSV35ws50hjnKNNcY41xTnaGKclpTIQkdXUEy0iIrLHNCXL+ViynI+daAJgYnaeC73jXBmY4M2BCd4cnOD71+6S9YN1vCzC0aY4RxsTXrBuinOwvlKrLIpsQCFaRERkD4iXlfD8oTqeP1SXO3Z/boG37kx6wXrQC9d/+loPs/NZwJsN5PGGSo41JryA3RTnSGOcylLFBxH9XyAiIrJHxaIRTrWlONWWyh1bWMzSfW8612N9ZWCC7755hz/v6s1d01ET41jTcrA+1hinrqpU5SCypyhEi4iISE4kHOJgfRUH66v4+MlmwJu7+u5EhisD6VywvtSfzg1eBKitjHK0KcHRxniuHKSjpoKwVlyUIqUQLSIiIg9kZjQkymhIlPHBI/tyxydm57nql4Is9Vz/8Ts3c3NYx6JhDjdU+QMYvYD9REOVVl2UoqDZOURERGTLzC1kuT40uWIA49WBCSYz3jzW4ZBxoK4iF6qP+rODaOVF2Yk0O4eIiIhsi2gkxLGmBMeaErlj2ayjb2zGKwfxBzC+/M49vvFGf+6apkSZVw7ih+pjTZp2T3Y2hWgREREpqFDIaKuJ0VYT48NPNuaO35vK5EL1lXWm3SsJGzUVpdRV+Vul91hbGaWuqix3vLYySmVpRIFbtpVCtIiIiASiprJ0zbR7M3OLXLvjBeq+sRmGJzMMT2a4OzHL5f4096bnWMyuLUUtKwmtCtorw3dt3jnVZMtWUIgWERGRHaM8Gl4z7V6+xaxj7P4cI1OZXMAenswsP5/KcGtkmnPdY4xOz637HlVlkZVBe/Wjv1VXRLXYjGxIIVpERER2jXDIqK30AvDhhgdfO7+Y5d7U3JqQnf94dWCCFyczuYGP+cwgFYuuCNdeKclS6C7LHUvFooQ0nd+eohAtIiIiRakkHMpNzfcws/OLK0N2fvD2j/f0TDM0kSGzkF3z+mgkxOGGKo43J3iyOcHxpgSPN1RSGlHpSLFSiBYREZE9r6wkTGt1jNbq2AOvc84xlVnwQ/acH7Jn6R+f4crABN+6MMCfvnob8AZGPtFQxfGmRC5ca57s4qEQLSIiIvKIzIyqshKqykrYX7f2vHOO3tEZLvWnudSf5spAmu9cucOfnfOWTY+EjEP7qjjeFOfJFi9cH2mIUx5VsN5ttNiKiIiISAE55+gfn+GyH6wv90/kZhoBr877YF0lx5sTHG+O82RzgiONcSpK1dcZNC22IiIiIhIQM6MlFaMlFeNDx715sp1zDKa9afsu96e5PDDBi9eH+csf9fmvgQN1lTzZnOBYkxesjzUnqFSw3jH0X0JERERkm5kZTclympLl/Myx5WlGlubDvuSH6/yVHc3gsZqKXI+195ggXlYS1MfY0xSiRURERHaIffEy9sXL+OCRfbljw5OZXI/1pf40Xd2jfPPCQO58e01sxawgx5vjJGPRIJq/pyhEi4iIiOxgdVWlfOBwPR84XJ87dm8qw+WBiVy4vtA7zl9fHMydb0mVe6G6eXlmkOoKBeutpBAtIiIissvUVJbyk4/X8ZOPL08RMn5/jsv9E14pyIAXrr99+U7ufFOiLBeoD9ZX5qb0S5SrHOTHoRAtIiIiUgSSsSjPHarluUO1uWPpmXmu+IF6aVaQ7755d8Xr4mURL1CnYrRWl6/Yb0nFNK/1BhSiRURERIpUoryEZw7U8syB5WA9lVmge2SavrH73B69T+/oDL1j97k+NMkP3hpasyJjXVUpraly2vye69ZUjJbqclpTMRoTZUTCoe3+WDuCQrSIiIjIHlJZGsnVSq+WzTpGpjL0jvnhevR+br+rZ4z/c3GQxezyGiPhkNGULPN6rvN6slv8/brKUsxsOz/etlGIFhEREREAQiGjPl5GfbyMM+1rz88vZrmTnqV31O/FHlvuyX7h2hAjU5kV15eXhGlJLZWIrAzYrdWxXT09n0K0iIiIiDySknAoNyDxmXXOz8wt0jd2f92e7HPdo0zOLqy4PlFe4gXqVGxF0G6tjtGcLN/R9dgK0SIiIiKyJcqjYQ7tq+LQvqp1z6fvz/uh2gvXSzXZb92d5IVrQ8ytqsfeFy+lNRXjf/zjUzQmyrfjIzwyhWgRERER2RaJWAmJ2Mb12MNTmRW910v7VTuw7EMhWkREREQCFwpZbsXGzo7qoJvzUHtzThIRERERkXehYCHazL5oZkNmdnmD82ZmnzWzG2Z20cxOF6otIiIiIiJbqZA90V8CPvSA8x8GDvnbp4A/LGBbRERERES2TMFCtHPuRWD0AZd8HPiy87wCJM2ssVDtERERERHZKkHWRDcDvXnP+/xjIiIiIiI7WpAher01IN06xzCzT5lZl5l1DQ8PF7hZIiIiIiIPFmSI7gNa8563AAPrXeic+4JzrtM511lXV7ctjRMRERER2UiQIfqbwD/zZ+l4Ckg75wYDbI+IiIiIyCMp2GIrZvZV4P1ArZn1Ab8DlAA45z4P/F/gI8AN4D7wi4Vqi4iIiIjIVipYiHbOfeIh5x3wK4X680VERERECkUrFoqIiIiIbJJCtIiIiIjIJilEi4iIiIhsknmlybuHmQ0DPQH98bXASEB/drHTvS0c3dvC0b0tDN3XwtG9LRzd28IJ8t62O+fWnV9514XoIJlZl3OuM+h2FCPd28LRvS0c3dvC0H0tHN3bwtG9LZydem9VziEiIiIiskkK0SIiIiIim6QQvTlfCLoBRUz3tnB0bwtH97YwdF8LR/e2cHRvC2dH3lvVRIuIiIiIbJJ6okVERERENkkh+hGY2YfM7C0zu2Fmvxl0e4qFmbWa2Q/M7KqZXTGzzwTdpmJjZmEze8PMvhV0W4qJmSXN7Gtmds3/+/t00G0qFmb2L/2fB5fN7KtmVhZ0m3YrM/uimQ2Z2eW8Y9Vm9j0zu+4/poJs4261wb39z/7PhItm9g0zSwbZxt1qvXubd+7XzcyZWW0QbVtNIfohzCwM/AHwYeAo8AkzOxpsq4rGAvCvnXNHgKeAX9G93XKfAa4G3Ygi9PvAd5xzh4ET6B5vCTNrBn4N6HTOHQfCwM8H26pd7UvAh1Yd+03gBefcIeAF/7ls3pdYe2+/Bxx3zr0HeBv4re1uVJH4EmvvLWbWCvw0cHu7G7QRheiHey9wwzl30zk3B/wZ8PGA21QUnHODzrkf+fuTeEGkOdhWFQ8zawF+FvijoNtSTMwsDrwP+GMA59ycc2482FYVlQhQbmYRIAYMBNyeXcs59yIwuurwx4E/8ff/BPiH29qoIrHevXXOfdc5t+A/fQVo2faGFYEN/t4C/Hfg3wI7ZjCfQvTDNQO9ec/7UNDbcmbWAZwCXg22JUXl9/B+4GSDbkiR2Q8MA//LL5X5IzOrCLpRxcA51w/8F7yepkEg7Zz7brCtKjr7nHOD4HVkAPUBt6dY/RLw7aAbUSzM7GNAv3PuQtBtyacQ/XC2zrEd86+gYmBmlcBfAv/COTcRdHuKgZl9FBhyzr0edFuKUAQ4Dfyhc+4UMI1+Jb4l/PrcjwOPAU1AhZn9k2BbJbI5ZvbbeOWKXwm6LcXAzGLAbwP/Lui2rKYQ/XB9QGve8xb068UtY2YleAH6K865rwfdniLyLPAxM+vGK0H6KTP738E2qWj0AX3OuaXfmnwNL1TLu/cPgFvOuWHn3DzwdeCZgNtUbO6aWSOA/zgUcHuKipl9Evgo8AtOcwhvlQN4/7C+4H+ntQA/MrOGQFuFQvSjOAccMrPHzCyKN8jlmwG3qSiYmeHVlV51zv23oNtTTJxzv+Wca3HOdeD9nf2+c049elvAOXcH6DWzJ/xDHwTeDLBJxeQ28JSZxfyfDx9Egza32jeBT/r7nwT+KsC2FBUz+xDwG8DHnHP3g25PsXDOXXLO1TvnOvzvtD7gtP+zOFAK0Q/hDxL4VeBv8H6Y/4Vz7kqwrSoazwL/FK+X9Ly/fSToRok8gn8OfMXMLgIngf8YcHuKgt+7/zXgR8AlvO+oHblS2W5gZl8FXgaeMLM+M/tl4HeBnzaz63gzHfxukG3crTa4t58DqoDv+d9nnw+0kbvUBvd2R9KKhSIiIiIim6SeaBERERGRTVKIFhERERHZJIVoEREREZFNUogWEREREdkkhWgRERERkU1SiBYR2UXMbDFvSsjzZrZlqyWaWYeZXd6q9xMRKWaRoBsgIiKbMuOcOxl0I0RE9jr1RIuIFAEz6zaz/2Rmr/nbQf94u5m9YGYX/cc2//g+M/uGmV3wt6XltcNm9j/N7IqZfdfMygP7UCIiO5hCtIjI7lK+qpzj5/LOTTjn3ou3ctrv+cc+B3zZOfce4CvAZ/3jnwX+zjl3AjgNLK3Eegj4A+fcMWAc+EcF/jwiIruSViwUEdlFzGzKOVe5zvFu4KecczfNrAS445yrMbMRoNE5N+8fH3TO1ZrZMNDinMvkvUcH8D3n3CH/+W8AJc65/1D4TyYisruoJ1pEpHi4DfY3umY9mbz9RTR2RkRkXQrRIiLF4+fyHl/2938I/Ly//wvAS/7+C8CnAcwsbGbx7WqkiEgxUA+DiMjuUm5m5/Oef8c5tzTNXamZvYrXQfIJ/9ivAV80s38DDAO/6B//DPAFM/tlvB7nTwODBW+9iEiRUE20iEgR8GuiO51zI0G3RURkL1A5h4iIiIjIJqknWkRERERkk9QTLSIiIiKySQrRIiIiIiKbpBAtIiIiIrJJCtEiIiIiIpukEC0iIiIiskkK0SIiIiIim/T/AZnq0+C6OctkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation losses\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Average batch Training and validation loss in each epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(training_losses)\n",
    "plt.plot(validation_losses)\n",
    "plt.legend([\"Training loss\",\"Validation loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracies\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.title(\"Training and validation accuracy in each epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(training_accuracies)\n",
    "plt.plot(validation_accuracies)\n",
    "plt.legend([\"Training accuracy\",\"Validation accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load saved checkpoint\n",
    "# checkpoint_path = RESULTS_DIR + \"2020-03-21-_04-30-14\" + \"/model_checkpoint.pth\"\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# next_epoch_idx = checkpoint['next_epoch_idx']\n",
    "# val_accuracy = checkpoint['val_accuracy']\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# print(\"=> loaded checkpoint '{}' (next_epoch_idx {})\".format(checkpoint_path, next_epoch_idx))\n",
    "\n",
    "# # # Load saved model\n",
    "# # path = RESULTS_DIR + \"2020-03-21-_04-30-14\" + \"/bilstm_video_model.pth\"\n",
    "# # model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done predicting on validation set. Saved to ../results/2020-04-05_18-03-28/val_results.csv\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "try:\n",
    "    val_f.close()    \n",
    "except(NameError):\n",
    "    ;   \n",
    "val_f = open(VALIDATION_DATA, 'rb')\n",
    "\n",
    "y = {'Actual': [], 'Predicted': []}\n",
    "\n",
    "is_file_end = False\n",
    "while not is_file_end:\n",
    "    video, is_file_end = get_next_video_data(val_f)\n",
    "    if is_file_end:\n",
    "        break\n",
    "\n",
    "    inputs, labels, segment_indices = transform_to_inputs(video)\n",
    "\n",
    "    outputs = model(inputs, segment_indices)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    y['Actual'].extend(labels.tolist())\n",
    "    y['Predicted'].extend(predicted.tolist())\n",
    "    \n",
    "y_df = pd.DataFrame(y)\n",
    "path = RESULTS_DIR + model_time + \"/val_results.csv\"        \n",
    "y_df.to_csv(path, encoding='utf-8', index=False)\n",
    "\n",
    "print('Done predicting on validation set. Saved to', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro f1 Score= 0.4029\n",
      "Macro Precision= 0.4369\n",
      "Macro Recall= 0.4204\n",
      "\n",
      "Micro f1 Score= 0.5480\n",
      "Micro Precision= 0.5480\n",
      "Micro Recall= 0.5480\n",
      "\n",
      "Accuracy: 0.5480\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "\n",
    "print('\\nMacro f1 Score= %.4f' % f1_score(y['Actual'], y['Predicted'], average=\"macro\"))\n",
    "print('Macro Precision= %.4f' % precision_score(y['Actual'], y['Predicted'], zero_division=0, average=\"macro\"))\n",
    "print('Macro Recall= %.4f' % recall_score(y['Actual'], y['Predicted'], average=\"macro\")) \n",
    "\n",
    "print('\\nMicro f1 Score= %.4f' % f1_score(y['Actual'], y['Predicted'], average=\"micro\"))\n",
    "print('Micro Precision= %.4f' % precision_score(y['Actual'], y['Predicted'], zero_division=0, average=\"micro\"))\n",
    "print('Micro Recall= %.4f' % recall_score(y['Actual'], y['Predicted'], average=\"micro\")) \n",
    "\n",
    "print('\\nAccuracy: %.4f' % accuracy_score(y['Actual'], y['Predicted']))\n",
    "\n",
    "# Computes the average AUC of all possible pairwise combinations of classes. \n",
    "# Insensitive to class imbalance when average == 'macro'.\n",
    "# print(roc_auc_score(y['Actual'], y['Predicted'], multi_class='ovo', average='macro')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test data predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done predicting on test data. Saved to ../results/2020-04-05_18-03-28/2020-04-05_18-03-28_predictions_submission.csv\n"
     ]
    }
   ],
   "source": [
    "NUM_TEST_SEGMENTS = 1284\n",
    "\n",
    "model.eval()\n",
    "\n",
    "try:\n",
    "    test_f.close()    \n",
    "except(NameError):\n",
    "    pass   \n",
    "test_f = open(TEST_DATA, 'rb')\n",
    "\n",
    "y_pred = {'Id': np.arange(NUM_TEST_SEGMENTS), 'Category': []}\n",
    "\n",
    "def transform_to_test_inputs(video):\n",
    "    segments = [] # segments (list of frames) in the video\n",
    "    segment_indices = []\n",
    "    offset = 0\n",
    "    for segment_num in range(len(video)):\n",
    "        segments.append(video[segment_num])\n",
    "        segment_indices.append((offset, offset + video[segment_num].shape[0]))\n",
    "\n",
    "        offset += video[segment_num].shape[0]\n",
    "\n",
    "    # Load frames as tensors with gradient accumulation abilities\n",
    "    input_frames = torch.cat(segments, 0).unsqueeze(0).requires_grad_().cuda() # unsqueeze to add batch dim\n",
    "    segment_indices = torch.IntTensor(segment_indices).cuda()\n",
    "    \n",
    "    return input_frames, segment_indices\n",
    "        \n",
    "is_end_reached = False\n",
    "while not is_end_reached:\n",
    "    video, is_end_reached = get_next_video_data(test_f)\n",
    "\n",
    "    if is_end_reached:\n",
    "        break\n",
    "\n",
    "    inputs, segment_indices = transform_to_test_inputs(video)\n",
    "    \n",
    "    outputs = model(inputs, segment_indices)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    y_pred['Category'].extend(predicted.tolist())\n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "path = RESULTS_DIR + model_time + \"/\" + model_time + \"_predictions_submission.csv\"\n",
    "y_pred_df.to_csv(path, encoding='utf-8', index=False)\n",
    "\n",
    "print('Done predicting on test data. Saved to', path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
